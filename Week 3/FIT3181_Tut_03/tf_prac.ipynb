{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:#0b486b\">  FIT3181: Deep Learning (2022)</span>\n",
    "***\n",
    "*CE/Lecturer (Clayton):*  **Dr Trung Le** | trunglm@monash.edu <br/>\n",
    "*Lecturer (Malaysia):*  **Dr Lim Chern Hong** | lim.chernhong@monash.edu <br/>  <br/>\n",
    "*Tutor:*  **Mr Thanh Nguyen** \\[Thanh.Nguyen4@monash.edu \\] |**Mr Tuan Nguyen**  \\[tuan.ng@monash.edu \\] |**Mr Anh Bui** \\[tuananh.bui@monash.edu\\] | **Dr Binh Nguyen** \\[binh.nguyen1@monash.edu \\] | **Mr Md Mohaimenuzzaman** \\[md.mohaimen@monash.edu \\] |**Mr James Tong** \\[james.tong1@monash.edu \\]\n",
    "<br/> <br/>\n",
    "Faculty of Information Technology, Monash University, Australia\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The tutorial will be using `sklearn` to load the dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import numpy as np\n",
    "from sklearn.datasets import load_svmlight_file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X data shape:(15000, 16)\n",
      "y data shape:(15000, 1)\n",
      "Number of unique classes: 26\n",
      "Checkout label classes: [ 1.  2.  3.  4.  5.  6.  7.  8.  9. 10. 11. 12. 13. 14. 15. 16. 17. 18.\n",
      " 19. 20. 21. 22. 23. 24. 25. 26.]\n"
     ]
    }
   ],
   "source": [
    "data_file_name = \"letter_scale.libsvm\"\n",
    "data_file = os.path.abspath(\"./Data/\" + data_file_name)\n",
    "X_data, y_data = load_svmlight_file(data_file)\n",
    "X_data = X_data.toarray() \n",
    "y_data = y_data.reshape(y_data.shape[0], -1)\n",
    "\n",
    "# Getting the shape of data x and y\n",
    "print(f\"X data shape:{X_data.shape}\")\n",
    "print(f\"y data shape:{y_data.shape}\")\n",
    "print(f\"Number of unique classes: {len(np.unique(y_data))}\")\n",
    "print(f\"Checkout label classes: {np.unique(y_data)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X Sample data:[-0.733333  -0.466667  -0.466667  -0.6       -0.733333  -0.0666667\n",
      "  0.0666667 -0.733333   0.2        0.466667  -0.0666667 -0.0666667\n",
      " -0.866667   0.0666667 -0.333333  -0.2      ]\n",
      "y Sample data:[26.]\n"
     ]
    }
   ],
   "source": [
    "# What does data x and y have?\n",
    "print(f\"X Sample data:{X_data[0]}\") # Condensed data from dataset\n",
    "print(f\"y Sample data:{y_data[0]}\") # Label from dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using `sklearn` to yet again split the dataset into train, validation and test sets. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn import preprocessing\n",
    "\n",
    "def train_valid_test_split(data, target, train_size, test_size):\n",
    "    validation_size = 1 - (train_size + test_size)\n",
    "    \n",
    "    # Performing the normal split, then only split the training set again as validation set\n",
    "    X1, X_test, y1, y_test = train_test_split(data, target, test_size=test_size, random_state=42)\n",
    "    \n",
    "    X_train, X_valid, y_train, y_valid = train_test_split(X1, y1, test_size=float(validation_size)/(validation_size + train_size))\n",
    "    \n",
    "    return X_train, X_valid, X_test, y_train, y_valid, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "how y_data looks like: [25 15 18 ...  0 11 21]\n"
     ]
    }
   ],
   "source": [
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(y_data.ravel())\n",
    "y_data = le.transform(y_data.ravel())\n",
    "print(f\"how y_data looks like: {y_data}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12000, 16) (1500, 16) (1500, 16)\n",
      "(12000,) (1500,) (1500,)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_valid, X_test, y_train, y_valid, y_test = train_valid_test_split(X_data,y_data, train_size=0.8, test_size=0.1)\n",
    "y_train = y_train.reshape(-1)\n",
    "y_test = y_test.reshape(-1)\n",
    "y_valid = y_valid.reshape(-1)\n",
    "\n",
    "print(X_train.shape, X_valid.shape, X_test.shape)\n",
    "print(y_train.shape, y_valid.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "375/375 [==============================] - 1s 877us/step - loss: 2.7968 - accuracy: 0.1863 - val_loss: 2.2122 - val_accuracy: 0.3433\n",
      "Epoch 2/20\n",
      "375/375 [==============================] - 0s 642us/step - loss: 1.8395 - accuracy: 0.4452 - val_loss: 1.7003 - val_accuracy: 0.5087\n",
      "Epoch 3/20\n",
      "375/375 [==============================] - 0s 639us/step - loss: 1.5493 - accuracy: 0.5297 - val_loss: 1.5596 - val_accuracy: 0.5393\n",
      "Epoch 4/20\n",
      "375/375 [==============================] - 0s 644us/step - loss: 1.4327 - accuracy: 0.5682 - val_loss: 1.4621 - val_accuracy: 0.5673\n",
      "Epoch 5/20\n",
      "375/375 [==============================] - 0s 703us/step - loss: 1.3478 - accuracy: 0.5988 - val_loss: 1.3820 - val_accuracy: 0.5907\n",
      "Epoch 6/20\n",
      "375/375 [==============================] - 0s 650us/step - loss: 1.2738 - accuracy: 0.6235 - val_loss: 1.3186 - val_accuracy: 0.6060\n",
      "Epoch 7/20\n",
      "375/375 [==============================] - 0s 647us/step - loss: 1.2095 - accuracy: 0.6413 - val_loss: 1.2639 - val_accuracy: 0.6427\n",
      "Epoch 8/20\n",
      "375/375 [==============================] - 0s 663us/step - loss: 1.1556 - accuracy: 0.6568 - val_loss: 1.2061 - val_accuracy: 0.6453\n",
      "Epoch 9/20\n",
      "375/375 [==============================] - 0s 652us/step - loss: 1.1129 - accuracy: 0.6681 - val_loss: 1.1663 - val_accuracy: 0.6573\n",
      "Epoch 10/20\n",
      "375/375 [==============================] - 0s 647us/step - loss: 1.0734 - accuracy: 0.6802 - val_loss: 1.1299 - val_accuracy: 0.6680\n",
      "Epoch 11/20\n",
      "375/375 [==============================] - 0s 671us/step - loss: 1.0419 - accuracy: 0.6930 - val_loss: 1.0917 - val_accuracy: 0.6687\n",
      "Epoch 12/20\n",
      "375/375 [==============================] - 0s 650us/step - loss: 1.0103 - accuracy: 0.6970 - val_loss: 1.0680 - val_accuracy: 0.6820\n",
      "Epoch 13/20\n",
      "375/375 [==============================] - 0s 655us/step - loss: 0.9840 - accuracy: 0.7063 - val_loss: 1.0332 - val_accuracy: 0.6940\n",
      "Epoch 14/20\n",
      "375/375 [==============================] - 0s 660us/step - loss: 0.9585 - accuracy: 0.7140 - val_loss: 1.0341 - val_accuracy: 0.6920\n",
      "Epoch 15/20\n",
      "375/375 [==============================] - 0s 652us/step - loss: 0.9382 - accuracy: 0.7188 - val_loss: 1.0003 - val_accuracy: 0.6953\n",
      "Epoch 16/20\n",
      "375/375 [==============================] - 0s 652us/step - loss: 0.9193 - accuracy: 0.7221 - val_loss: 0.9854 - val_accuracy: 0.6953\n",
      "Epoch 17/20\n",
      "375/375 [==============================] - 0s 652us/step - loss: 0.8995 - accuracy: 0.7283 - val_loss: 0.9694 - val_accuracy: 0.7067\n",
      "Epoch 18/20\n",
      "375/375 [==============================] - 0s 650us/step - loss: 0.8825 - accuracy: 0.7352 - val_loss: 0.9357 - val_accuracy: 0.7133\n",
      "Epoch 19/20\n",
      "375/375 [==============================] - 0s 652us/step - loss: 0.8656 - accuracy: 0.7392 - val_loss: 0.9208 - val_accuracy: 0.7247\n",
      "Epoch 20/20\n",
      "375/375 [==============================] - 0s 650us/step - loss: 0.8518 - accuracy: 0.7442 - val_loss: 0.9177 - val_accuracy: 0.7220\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1aef82333d0>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf \n",
    "from tensorflow.keras.layers import Dense, Flatten \n",
    "from tensorflow.keras.models import Sequential \n",
    "\n",
    "# Using `tf.keras.Model as inheritance`\n",
    "class MyDNN(tf.keras.Model):\n",
    "    def __init__(self, n_classes= 26):\n",
    "        super(MyDNN, self).__init__()\n",
    "        self.n_classes = n_classes\n",
    "        self.dense1 = tf.keras.layers.Dense(units=10, activation= 'relu')\n",
    "        self.dense2 = tf.keras.layers.Dense(units=20, activation= 'relu')\n",
    "        self.dense3 = tf.keras.layers.Dense(units=15, activation= 'relu')\n",
    "        self.dense4 = tf.keras.layers.Dense(units=self.n_classes, activation= 'softmax')\n",
    "    \n",
    "    def call(self,X): #X is the input, method call specifies how to compute the output from the input X\n",
    "        h = self.dense1(X)\n",
    "        h = self.dense2(h)\n",
    "        h = self.dense3(h)\n",
    "        h = self.dense4(h)\n",
    "        return h\n",
    "dnn_model = MyDNN(n_classes= 26)\n",
    "dnn_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "dnn_model.fit(x=X_train, y=y_train, batch_size=32, \n",
    "                        epochs=20, \n",
    "                        validation_data=(X_valid, y_valid))\n",
    "         \n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: train acc=0.7338, train loss=0.9215 | valid acc=0.7113, valid loss= 0.9923\n",
      "Epoch 2: train acc=0.7393, train loss=0.8966 | valid acc=0.7207, valid loss= 0.9647\n",
      "Epoch 3: train acc=0.7456, train loss=0.8734 | valid acc=0.7260, valid loss= 0.9404\n",
      "Epoch 4: train acc=0.7497, train loss=0.8537 | valid acc=0.7300, valid loss= 0.9197\n",
      "Epoch 5: train acc=0.7548, train loss=0.8361 | valid acc=0.7387, valid loss= 0.9019\n",
      "Epoch 6: train acc=0.7575, train loss=0.8202 | valid acc=0.7393, valid loss= 0.8860\n",
      "Epoch 7: train acc=0.7604, train loss=0.8068 | valid acc=0.7400, valid loss= 0.8723\n",
      "Epoch 8: train acc=0.7638, train loss=0.7942 | valid acc=0.7420, valid loss= 0.8595\n",
      "Epoch 9: train acc=0.7664, train loss=0.7825 | valid acc=0.7420, valid loss= 0.8476\n",
      "Epoch 10: train acc=0.7682, train loss=0.7728 | valid acc=0.7467, valid loss= 0.8372\n",
      "Epoch 11: train acc=0.7709, train loss=0.7627 | valid acc=0.7493, valid loss= 0.8269\n",
      "Epoch 12: train acc=0.7727, train loss=0.7537 | valid acc=0.7493, valid loss= 0.8176\n",
      "Epoch 13: train acc=0.7751, train loss=0.7444 | valid acc=0.7513, valid loss= 0.8087\n",
      "Epoch 14: train acc=0.7768, train loss=0.7364 | valid acc=0.7547, valid loss= 0.8006\n",
      "Epoch 15: train acc=0.7799, train loss=0.7281 | valid acc=0.7573, valid loss= 0.7923\n",
      "Epoch 16: train acc=0.7823, train loss=0.7203 | valid acc=0.7613, valid loss= 0.7837\n",
      "Epoch 17: train acc=0.7843, train loss=0.7129 | valid acc=0.7613, valid loss= 0.7760\n",
      "Epoch 18: train acc=0.7876, train loss=0.7051 | valid acc=0.7640, valid loss= 0.7678\n",
      "Epoch 19: train acc=0.7893, train loss=0.6983 | valid acc=0.7660, valid loss= 0.7610\n",
      "Epoch 20: train acc=0.7913, train loss=0.6917 | valid acc=0.7693, valid loss= 0.7542\n"
     ]
    }
   ],
   "source": [
    "n_epochs =20\n",
    "batch_size = 32\n",
    "for epoch in range(n_epochs):\n",
    "    for idx_start in range(0, X_train.shape[0], batch_size):\n",
    "        idx_end = min(X_train.shape[0], idx_start + batch_size)\n",
    "        X_batch, y_batch = X_train[idx_start:idx_end], y_train[idx_start:idx_end]\n",
    "        train_loss_batch = dnn_model.train_on_batch(X_batch, y_batch)  #return the batch loss\n",
    "        \n",
    "    train_loss, train_acc = dnn_model.evaluate(x= X_train, y= y_train, batch_size= 64, verbose= 0)\n",
    "    valid_loss, valid_acc = dnn_model.evaluate(x= X_valid, y= y_valid, batch_size= 64, verbose= 0)\n",
    "    print('Epoch {}: train acc={:.4f}, train loss={:.4f} | valid acc={:.4f}, valid loss= {:.4f}'.format(epoch +1, \n",
    "                                                                                                        train_acc, \n",
    "                                                                                                        train_loss, \n",
    "                                                                                                        valid_acc, \n",
    "                                                                                                        valid_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.9 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b916ba2c14536b214077dfec6c206136f3cd9dd298193f9fd8924ac064eebdc3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
