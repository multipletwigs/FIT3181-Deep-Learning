{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:#0b486b\">  FIT3181: Deep Learning (2022)</span>\n",
    "***\n",
    "*CE/Lecturer:* Dr **Trung Le** | trunglm@monash.edu <br/>\n",
    "*Head Tutor:* Mr **Thanh Nguyen** | thanh.nguyen4@monash.edu  <br/>\n",
    "<br/>\n",
    "Department of Data Science and AI, Faculty of Information Technology, Monash University, Australia\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:#0b486b\">  Student Information</span>\n",
    "***\n",
    "Surname: **Khong**  <br/>\n",
    "Firstname: **Lap Hoe**    <br/>\n",
    "Student ID: **32114818**    <br/>\n",
    "Email: **lkho007@student.monash.edu**    <br/>\n",
    "Your tutorial time: **Tuesday 2PM**    <br/>\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:#0b486b\">Deep Neural Networks</span>\n",
    "### Due: <span style=\"color:red\">11:59pm Sunday, 18 September 2022</span>  (Sunday)\n",
    "\n",
    "#### <span style=\"color:red\">Important note:</span> This is an **individual** assignment. It contributes **20%** to your final mark. Read the assignment instruction carefully."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:#0b486b\">Instruction</span>\n",
    "\n",
    "This notebook has been prepared for your to complete Assignment 1. The theme of this assignment is about practical machine learning knowledge and skills in deep neural networks, including feedforward and convolutional neural networks. Some sections have been partially completed to help you get\n",
    "started. **The total marks for this notebook is 100**.\n",
    "\n",
    "* Before you start, read the entire notebook carefully once to understand what you need to do. <br/>\n",
    "\n",
    "* For each cell marked with **#YOU ARE REQUIRED TO INSERT YOUR CODES IN THIS CELL**, there will be places where you **must** supply your own codes when instructed. <br>\n",
    "\n",
    "This assignment contains **three** parts:\n",
    "\n",
    "* Part 1: Questions on theory and knowledge on machine learning and deep learning **[30 points], 30%**\n",
    "* Part 2: Coding assessment on TensorFlow for Deep Neural Networks (DNN) **[30 points], 30%**\n",
    "* Part 3: Coding assessment on TensorFlow for Convolution Neural Networks (CNN) **[40 points], 40%**\n",
    "\n",
    "**Hint**: This assignment was essentially designed based on the lectures and tutorials sessions covered from Week 1 to Week 6. You are strongly recommended to go through these contents thoroughly which might help you to complete this assignment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:#0b486b\">What to submit</span>\n",
    "\n",
    "This assignment is to be completed individually and submitted to Moodle unit site. **By the due date, you are required to submit one  <span style=\"color:red; font-weight:bold\">single zip file, named xxx_assignment01_solution.zip</span> where `xxx` is your student ID, to the corresponding Assignment (Dropbox) in Moodle**. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***For example, if your student ID is <span style=\"color:red; font-weight:bold\">12356</span>, then gather all of your assignment solution to folder, create a zip file named <span style=\"color:red; font-weight:bold\">123456_assignment01_solution.zip</span> and submit this file.***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Within this zip folder, you **must** submit the following files:\n",
    "1.\t**Assignment01_solution.ipynb**:  this is your Python notebook solution source file.\n",
    "1.\t**Assignment01_output.html**: this is the output of your Python notebook solution *exported* in html format.\n",
    "1.\tAny **extra files or folder** needed to complete your assignment (e.g., images used in your answers)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the notebook is quite big to load and work together, one recommended option is to split solution into three parts and work on them seperately. In that case, replace **Assignment01_solution.ipynb** by three notebooks: **Assignment01_Part1_solution.ipynb**, **Assignment01_Part2_solution.ipynb** and **Assignment01_Part3_solution.ipynb**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**You can run your codes on Google Colab. In this case, you need to capture the screenshots of your Google Colab model training and put in corresponding places in your Jupyter notebook. You also need to store your trained models to folder <span style=\"color:red; font-weight:bold\">*./models*</span> with recognizable file names (e.g., Part3_Sec3_2_model.h5).** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:#0b486b\">Part 1: Theory and Knowledge Questions</span>\n",
    "<div style=\"text-align: right\"><span style=\"color:red; font-weight:bold\">[Total marks for this part: 30 points]<span></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first part of this assignment is for you to demonstrate your knowledge in deep learning that you have acquired from the lectures and tutorials materials. Most of the contents in this assignment are drawn from **the lectures and tutorials from weeks 1 to 3**. Going through these materials before attempting this part is highly recommended."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  <span style=\"color:red\">**Question 1.1**</span> **Activation function plays an important role in modern Deep NNs. For each of the activation function below, state its output range, find its derivative (show your steps), and plot the activation fuction and its derivative**\n",
    "\n",
    "<span style=\"color:red\">**(a)**</span> Leaky ReLU: $\\text{LeakyReLU}\\left(x\\right)=\\begin{cases}\n",
    "0.01x & \\text{if}\\,x<0\\\\\n",
    "x & \\text{otherwise}\n",
    "\\end{cases}$ \n",
    "<div style=\"text-align: right\"><span style=\"color:red\">[1.5 points]</span></div> \n",
    "\n",
    "<span style=\"color:red\">**(b)**</span> Softplus: $\\text{Softplus}\\left(x\\right)=\\text{ln}\\left(1+e^{x}\\right)$\n",
    "<div style=\"text-align: right\"><span style=\"color:red\">[1.5 points]</span></div> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:#0b486b\"> **Numpy is possibly being used in the following questions. You need to import numpy here.** </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1.1 Submission\n",
    "(a)\n",
    "\n",
    "The output range of $\\text{LeakyReLu}$ is $(-\\infty, +\\infty)$.\n",
    "\n",
    "The derivative of $\\text{LeakyReLu}$ is $\\text{LeakyReLu'(x)}$ $\\begin{cases}\n",
    "0.01 & \\text{if}\\,x<0\\\\\n",
    "1 & \\text{otherwise}\n",
    "\\end{cases}$ \n",
    "\n",
    "There's not much derivative steps to show for this simple function, but take the coefficient wrt $x$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "import numpy as np "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Obtaining values in the rang of -10 to 10\n",
    "x_val = np.linspace(-10, 10, 100) \n",
    "\n",
    "# Activation function\n",
    "LeakyReLU_activation = lambda x: 0.01 * x if x < 0 else x\n",
    "\n",
    "# Derivative function\n",
    "LeakyReLU_derivative = lambda x: 0.01 if x < 0 else 1 \n",
    "\n",
    "# Plots of activation and its derivative\n",
    "plt.plot(x_val, list(map(LeakyReLU_activation, x_val)), linewidth=2)\n",
    "plt.plot(x_val, list(map(LeakyReLU_derivative, x_val)), linewidth=2)\n",
    "plt.title(label=\"LeakyReLU and LeakyReKU' Output Plot\")\n",
    "plt.xlabel(\"x_input\")\n",
    "plt.ylabel(\"y_output\")\n",
    "plt.legend([\"LeakyReLU\", \"LeakyReLU'\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(b)\n",
    "\n",
    "The output range of softplus is $(0, +\\infty)$\n",
    "\n",
    "The derivative of softplus is as follows. \n",
    "\n",
    "$\\text{1. The derivative of softplus is given by }\\frac{d (softplus)}{dx}. \\\\\n",
    "\\text{2. We can use chain rule to solve this problem, given that the softplus is a \\texttt{composite function}}. \\\\\n",
    "\\text{3. Let }(1+e^{x}) \\text{ be y.} \\\\\n",
    "\\text{4. Then solve for the derivative } \\text{through } \\frac{d (softplus)}{dx} = \\frac{d (softplus)}{dy} * \\frac{dy}{dx} \\\\\n",
    "5. \\frac{d (softplus)}{dx} = \\frac{\\ln{(y)}}{dy} * \\frac{d(1+e^{x})}{dx} \\\\\n",
    "6. \\frac{d (softplus)}{dx} = \\frac{1}{y} * e^{x} \\\\\n",
    "7. \\frac{d (softplus)}{dx} = \\frac{e^{x}}{1+e^{x}}$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Obtaining values in the rang of -10 to 10\n",
    "x_val = np.linspace(-10, 10, 100) \n",
    "\n",
    "# Activation function\n",
    "Softplus_activation = lambda x: np.emath.log(np.divide(1, (1 + np.exp(x))))\n",
    "\n",
    "# Derivative function\n",
    "Softplus_derivative = lambda x: np.divide(np.exp(x), (1 + np.exp(x)))\n",
    "\n",
    "# Plots of activation and its derivative\n",
    "plt.plot(x_val, list(map(Softplus_activation, x_val)), linewidth=2)\n",
    "plt.title(label=\"Softplus Output Plot\")\n",
    "plt.xlabel(\"x_input\")\n",
    "plt.ylabel(\"y_output\")\n",
    "plt.legend([\"Softplus\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot derivative \n",
    "plt.plot(x_val, list(map(Softplus_derivative, x_val)), linewidth=2)\n",
    "plt.xlabel(\"x_input\")\n",
    "plt.ylabel(\"y_output\")\n",
    "plt.legend([\"Softplus'\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  <span style=\"color:red\">**Question 1.2**</span> **Assume that we feed a data point $x$ with a ground-truth label $y=2$ to the feed-forward neural network with the ReLU activation function as shown in the following figure**\n",
    "<img src=\"Figures/Q2_P1.png\" width=\"500\" align=\"center\"/>\n",
    "\n",
    "\n",
    "<span style=\"color:red\">**(a)**</span>  What is the numerical value of the latent presentation $h^1(x)$?\n",
    "<div style=\"text-align: right\"><span style=\"color:red\">[1 point]</span></div> \n",
    "\n",
    "<span style=\"color:red\">**(b)**</span>  What is the numerical value of the latent presentation $h^2(x)$?\n",
    "<div style=\"text-align: right\"><span style=\"color:red\">[1 point]</span></div> \n",
    "\n",
    "<span style=\"color:red\">**(c)**</span>  What is the numerical value of the logit $h^3(x)$?\n",
    "<div style=\"text-align: right\"><span style=\"color:red\">[1 point]</span></div> \n",
    "\n",
    "\n",
    "<span style=\"color:red\">**(d)**</span>  What is the corresonding prediction probabilities $p(x)$?\n",
    "<div style=\"text-align: right\"><span style=\"color:red\">[1 point]</span></div> \n",
    "\n",
    "<span style=\"color:red\">**(e)**</span>  What is the cross-entropy loss caused by the feed-forward neural network at $(x,y)$? Remind that $y=2$.\n",
    "<div style=\"text-align: right\"><span style=\"color:red\">[1 point]</span></div> \n",
    "\n",
    "<span style=\"color:red\">**(e)**</span>  Assume that we are applying the label smoothing technique (i.e.,  [link for main paper](https://papers.nips.cc/paper/2019/file/f1748d6b0fd9d439f71450117eba2725-Paper.pdf) from Goeff Hinton) with $\\alpha = 0.1$. What is the relevant loss caused by the feed-forward neural network at $(x,y)$?\n",
    "<div style=\"text-align: right\"><span style=\"color:red\">[1 point]</span></div> \n",
    "\n",
    "\n",
    "**You need to show both formulas and numerical results for earning full mark. Although it is optional, it is great if you show your numpy code for your computation.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question 1.2 GLOBAL VARIABLES\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "X_INP = np.array([1, -1, 1], dtype='float64')\n",
    "X_INP = np.reshape(X_INP, (3, 1))\n",
    "Y_TRUE = 2\n",
    "\n",
    "W1_MAT = np.array([1, -1, 1, 1, -1, -1, 2, -1, 2, -1, -2, 1], dtype='float64')\n",
    "W1_MAT = np.reshape(W1_MAT, (4, 3))\n",
    "\n",
    "B1_MAT = np.array([1, 0, 1, 0], dtype='float64')\n",
    "B1_MAT = np.reshape(B1_MAT, (4, 1))\n",
    "\n",
    "W2_MAT = np.array([1, -1, -1, 2, 1, -1, 1, -1, -1, 2, -1, 2], dtype='float64') \n",
    "W2_MAT = np.reshape(W2_MAT, (3, 4))\n",
    "\n",
    "B2_MAT = np.array([1, 1, 0], dtype='float64')\n",
    "B2_MAT = np.reshape(B2_MAT, (3, 1))\n",
    "\n",
    "W3_MAT = np.array([1, -2, 1, 1, 2, -1, -1, 1, -1], dtype='float64') \n",
    "W3_MAT = np.reshape(W3_MAT, (3, 3))\n",
    "\n",
    "B3_MAT = np.reshape(np.array([0, 0, 0], dtype='float64'), (3, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4.],\n",
       "       [1.],\n",
       "       [6.],\n",
       "       [2.]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# (a) Latent presentation of h1 is as follows... \n",
    "h1 = np.matmul(W1_MAT, X_INP) + B1_MAT\n",
    "h1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2.],\n",
       "       [ 8.],\n",
       "       [-4.]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# (b) Latent presentation of h2 is as follows... \n",
    "h2 = np.matmul(W2_MAT, h1) + B2_MAT \n",
    "h2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-18.],\n",
       "       [ 22.],\n",
       "       [ 10.]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# (c)\n",
    "h3 = np.matmul(W3_MAT, h2) + B3_MAT \n",
    "h3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3,), dtype=float64, numpy=array([4.24832815e-18, 9.99993856e-01, 6.14417460e-06])>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# (d) Apply softmax to get probability\n",
    "tf.nn.softmax(h3.flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float64, numpy=6.144193477747432e-06>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# (e) Cross-entrophy \n",
    "# Since the label is y=2, we can one-hot the label first to y = [0,1,0] \n",
    "CE_loss = tf.nn.softmax_cross_entropy_with_logits(\n",
    "    [0,1,0], h3.flatten(), axis=-1, name=None\n",
    ")\n",
    "CE_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float64, numpy=1.7333394775268112>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# (f) Label-smoothing method, where there are 3 classes to predict will yield the following. \n",
    "def label_smoothing(y_labels, smoothing_factor, num_classes):\n",
    "    smooth_labels = y_labels * (1 - smoothing_factor) + smoothing_factor / num_classes\n",
    "    return smooth_labels \n",
    "\n",
    "smooth_labels = label_smoothing(np.array([0,1,0]), 0.1, 3) \n",
    "\n",
    "CE_loss = tf.nn.softmax_cross_entropy_with_logits(\n",
    "    smooth_labels, h3.flatten(), axis=-1, name=None\n",
    ")\n",
    "CE_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  <span style=\"color:red\">**Question 1.3**</span> **Assume that we are constructing a multilayered feed-forward neural network for a classification problem with three classes where the model parameters will be generated randomly using your student ID. The architecture of this network is ($3 (Input)\\rightarrow4(LeakyReLU)\\rightarrow 3(Output)$) as shown in the following figure. Note that the LeakyReLU has the same formula as the one in Q1.1.**\n",
    "\n",
    "\n",
    "<img src=\"Figures/Q3_P1.png\" width=\"500\" align=\"center\"/>\n",
    "\n",
    "We feed a feature vector $x=\\left[\\begin{array}{ccc}\n",
    "1 & -1 & 1.5\\end{array}\\right]^{T}$ with ground-truth label $y=3$ to the above network. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**You need to show both formulas, numerical results, and your numpy code for your computation for earning full marks.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Code to generate random matrices and biases for W1, b1, W2, b2\n",
    "import numpy as np\n",
    "student_id = 32114818           #insert your student id here for example 1234    \n",
    "np.random.seed(student_id)\n",
    "W1 = np.random.rand(4,3)\n",
    "b1 = np.random.rand(4,1)\n",
    "W2 = np.random.rand(3,4)\n",
    "b2 = np.random.rand(3,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Forward propagation**\n",
    "\n",
    "<span style=\"color:red\">**(a)**</span>  What is the value of $\\bar{h}^{1}(x)$?\n",
    "<div style=\"text-align: right\"><span style=\"color:red\">[1 point]</span></div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Show your fomular*\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.56751867],\n",
       "       [1.71830858],\n",
       "       [2.39623   ],\n",
       "       [1.05539234]])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show your code\n",
    "h1_lin = np.matmul(W1, np.array([[1], [-1], [1.5]])) + b1\n",
    "h1_lin\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:red\">**(b)**</span>  What is the value of $h^{1}(x)$?\n",
    "<div style=\"text-align: right\"><span style=\"color:red\">[1 point]</span></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Show your fomular*\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.56751867],\n",
       "       [1.71830858],\n",
       "       [2.39623   ],\n",
       "       [1.05539234]])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Show your code\n",
    "h1_act = np.array([LeakyReLU_activation(x[0]) for x in h1_lin])\n",
    "h1_act = h1_act.reshape(4,1)\n",
    "h1_act\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:red\">**(c)**</span>  What is the predicted value $\\hat{y}$?\n",
    "<div style=\"text-align: right\"><span style=\"color:red\">[1 point]</span></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Show your fomular*\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3,), dtype=float64, numpy=array([0.47310033, 0.23602163, 0.29087803])>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Show your code\n",
    "h2_lin = np.matmul(W2, h1_act) + b2\n",
    "h2_act = tf.nn.softmax(h2_lin.flatten())\n",
    "h2_act"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:red\">**(d)**</span>  Suppose that we use the cross-entropy (CE) loss. What is the value of the CE loss $l$?\n",
    "<div style=\"text-align: right\"><span style=\"color:red\">[1 point]</span></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Show your fomular*\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float64, numpy=1.234851234610139>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Show your code\n",
    "tf.nn.softmax_cross_entropy_with_logits(\n",
    "    [0,0,1], h2_lin.flatten(), axis=-1, name=None\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Backward propagation**\n",
    "\n",
    "<span style=\"color:red\">**(e)**</span> What are the derivatives $\\frac{\\partial l}{\\partial h^{2}},\\frac{\\partial l}{\\partial W^{2}}$, and $\\frac{\\partial l}{\\partial b^{2}}$? \n",
    "<div style=\"text-align: right\"><span style=\"color:red\">[6 points]</span></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Show your fomular*\n",
    "\n",
    "$\\text{CE loss} = \\text{KL divergence between } h^2 \\text{ and label y} + \\text{entropy of label y}$\n",
    "\n",
    "Here notice that the entropy for any one-hot unsmoothed label y, will always be 0. That leaves us with finding the KL-Divergence of the label and predicted distribution. \n",
    "\n",
    "$\\text{CE loss} = -\\log{1 * q_i}, \\text{where i is the index in which y at i = 1}$\\\n",
    "$\\frac{d(CE)}{d(h^3)}$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Show your code\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:red\">**(f)**</span> What are the derivatives $\\frac{\\partial l}{\\partial h^{1}}, \\frac{\\partial l}{\\partial \\bar{h}^{1}},\\frac{\\partial l}{\\partial W^{1}}$, and $\\frac{\\partial l}{\\partial b^{1}}$? \n",
    "<div style=\"text-align: right\"><span style=\"color:red\">[6 points]</span></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Show your fomular*\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Show your code\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**SGD update**\n",
    "\n",
    "<span style=\"color:red\">**(g)**</span> Assume that we use SGD with learning rate $\\eta=0.01$ to update the model parameters. What are the values of $W^2, b^2$ and $W^1, b^1$ after updating?\n",
    "<div style=\"text-align: right\"><span style=\"color:red\">[5 points]</span></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Show your fomular*\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Show your code\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:#0b486b\">Part 2: Deep Neural Networks (DNN) </span>\n",
    "<div style=\"text-align: right\"><span style=\"color:red; font-weight:bold\">[Total marks for this part: 30 points]<span></div>\n",
    "\n",
    "The first part of this assignment is for you to demonstrate your basis knowledge in deep learning that you have acquired from the lectures and tutorials materials. Most of the contents in this assignment are drawn from **the tutorials covered from weeks 1 to 4**. Going through these materials before attempting this assignment is highly recommended."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the first part of this assignment, you are going to work with the **FashionMNIST** dataset for *image recognition task*. It has the exact same format as MNIST (70,000 grayscale images of 28 × 28 pixels each with 10 classes), but the images represent fashion items rather than handwritten digits, so each class is more diverse, and the problem is significantly more challenging than MNIST."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  <span style=\"color:red\">**Question 2.1**</span>. Load the Fashion MNIST using Keras datasets\n",
    "\n",
    "<div style=\"text-align: right\"> <span style=\"color:red\">[5 points]</span> </div>\n",
    "\n",
    "We first use keras incoporated in TensorFlow 2.x for loading the training and testing sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(1234)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first use keras datasets in TF 2.x to load Fashion MNIST dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fashion_mnist = keras.datasets.fashion_mnist\n",
    "(X_train_full_img, y_train_full), (X_test_img, y_test) = fashion_mnist.load_data()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The shape of X_train_full_img is $(60000, 28, 28 )$ and that of X_test_img is $(10000, 28, 28)$. We next convert them to matrices of vectors and store in X_train_full and X_test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_train = X_train_full_img.shape[0]\n",
    "num_test = X_test_img.shape[0]\n",
    "X_train_full = X_train_full_img.reshape(num_train, -1)\n",
    "X_test = X_test_img.reshape(num_test, -1)\n",
    "\n",
    "# One-hot encode our data for label smoothing in the following section \n",
    "y_train_full_onehot = keras.utils.to_categorical(y_train_full)\n",
    "y_test_onehot = keras.utils.to_categorical(y_test)\n",
    "\n",
    "print(\"--BEFORE ONEHOT--\")\n",
    "print(f\"Training shape: {X_train_full.shape}, Training label shape: {y_train_full.shape}\")\n",
    "print(f\"Testing shape: {X_test.shape}, Testing label shape: {y_test.shape}\")\n",
    "\n",
    "print(\"--AFTER ONEHOT--\")\n",
    "print(f\"Training shape: {X_train_full.shape}, Training label shape: {y_train_full_onehot.shape}\")\n",
    "print(f\"Testing shape: {X_test.shape}, Testing label shape: {y_test_onehot.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  <span style=\"color:red\">**Question 2.2**</span>. Preprocess the dataset and split into training, validation, and testing datasets\n",
    "\n",
    "<div style=\"text-align: right\"> <span style=\"color:red\">[5 points]</span> </div>\n",
    "\n",
    "You need to write the code to address the following requirements:\n",
    "- Print out the dimensions of X_train_full and X_test\n",
    "- Use $10 \\%$ of X_train_full for validation and the rest of X_train_full for training. This splits X_train_full and y_train_full into X_train, y_train ($90 \\%$) and X_valid, y_valid ($10 \\%$).\n",
    "- Finally, scale the pixels of X_train, X_valid, and X_test to $[0,1]$) (i.e., $X = X/255.0$).\n",
    "\n",
    "You have now the separate training, validation, and testing sets for training your model.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "N = X_train_full.shape[0]\n",
    "i = math.floor(0.9*N)\n",
    "\n",
    "X_train, y_train = X_train_full[:i], y_train_full_onehot[:i]\n",
    "X_valid, y_valid = X_train_full[i:], y_train_full_onehot[i:]\n",
    "X_train, X_valid, X_test = X_train / 255.0, X_valid / 255.0, X_test / 255.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  <span style=\"color:red\">**Question 2.3**</span>. Visualize some images in the training set with labels\n",
    "\n",
    "<div style=\"text-align: right\"> <span style=\"color:red\">[5 points]</span> </div>\n",
    "\n",
    "You are required to write the code to show **random** $36$ images in X_train_full_img (which is an array of images) with labels as in the following figure. Note that the class names of Fashion MNIST are as follows \n",
    "- \"1:T-shirt/top\", \"2:Trouser\", \"3:Pullover\", \"4:Dress\", \"5:Coat\", \"6:Sandal\", \"7:Shirt\", \"8:Sneaker\", \"9:Bag\", \"10:Ankle boot\"\n",
    "\n",
    "<img src=\"Figures/Fashion_MNIST.png\" width=\"450\" align=\"center\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOU ARE REQUIRED TO INSERT YOUR CODES IN THIS CELL\n",
    "LABEL_DICT = {\"0\":\"T-shirt/top\", \"1\":\"Trouser\", \"2\":\"Pullover\", \"3\":\"Dress\", \"4\":\"Coat\", \"5\":\"Sandal\", \"6\":\"Shirt\", \"7\":\"Sneaker\", \"8\":\"Bag\", \"9\":\"Ankle boot\"}\n",
    "\n",
    "def display_image(images, label, num2display):\n",
    "    fig = plt.figure(figsize=(15,15))\n",
    "    for i in range(num2display):\n",
    "        p = fig.add_subplot(6,6,i+1,xticks=[],yticks=[])\n",
    "        p.imshow(images[i], cmap=\"Greys\")\n",
    "        p.set_title(f\"{i} - {LABEL_DICT[str(label[i])]}\",y=0, pad=-15)\n",
    "\n",
    "display_image(X_train_full_img, y_train_full, 36)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  <span style=\"color:red\">**Question 2.4**</span>. Write code for the feed-forward neural net using TF 2.x\n",
    "\n",
    "<div style=\"text-align: right\"> <span style=\"color:red\">[5 points]</span> </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now develop a feed-forward neural network with the architecture $784 \\rightarrow 20(ReLU) \\rightarrow 40(ReLU) \\rightarrow 10(softmax)$. You can choose your own way to implement your network and an optimizer of interest. You should train model in $20$ epochs and evaluate the trained model on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Insert your code here and you can add more cells if necessary\n",
    "class FASHION_MNIST_DNN(tf.keras.Model):\n",
    "    def __init__(self, n_classes=10, *args, **kwargs) -> None:\n",
    "        super(FASHION_MNIST_DNN, self).__init__(*args, **kwargs)\n",
    "        self.n_classes = n_classes\n",
    "        self.layer1 = tf.keras.layers.Dense(units=20, activation='relu', name=\"q2.4l1\", kernel_initializer=\"lecun_uniform\")\n",
    "        self.layer2 = tf.keras.layers.Dense(units=40, activation='relu',name=\"q2.4l2\",kernel_initializer=\"lecun_uniform\")\n",
    "        self.layer3= tf.keras.layers.Dense(units=n_classes, activation=\"softmax\",name=\"q2.4ol\",kernel_initializer=\"lecun_uniform\")\n",
    "    \n",
    "    def call(self, X):\n",
    "        h = self.layer1(X)\n",
    "        h = self.layer2(h)\n",
    "        h = self.layer3(h)\n",
    "        \n",
    "        return h \n",
    "\n",
    "dnn_model = FASHION_MNIST_DNN(n_classes=10, name=\"fashin_dnn_model\")\n",
    "dnn_model.compile(optimizer=keras.optimizers.Adam(learning_rate=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "dnn_model.fit(x=X_train, y=y_train, epochs=20, validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluating the trained model on the test set \n",
    "dnn_model.evaluate(x=X_test, y=y_test_onehot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  <span style=\"color:red\">**Question 2.5**</span>. Tuning hyper-parameters with grid search\n",
    "<div style=\"text-align: right\"> <span style=\"color:red\">[5 points]</span> </div>\n",
    "\n",
    "Assume that you need to tune the number of neurons on the first and second hidden layers $n_1 \\in \\{20, 40\\}$, $n_2 \\in \\{20, 40\\}$  and the used activation function  $act \\in \\{sigmoid, tanh, relu\\}$. The network has the architecture pattern $784 \\rightarrow n_1 (act) \\rightarrow n_2(act) \\rightarrow 10(softmax)$ where $n_1, n_2$, and $act$ are in their grides. Write the code to tune the hyper-parameters $n_1, n_2$, and $act$. Note that you can freely choose the optimizer and learning rate of interest for this task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Insert your code here. You can add more cells if necessary\n",
    "from typing import List\n",
    "import sklearn.model_selection as sk\n",
    "\n",
    "def generate_model(neurons: List[int], activation: str) -> tf.keras.models: \n",
    "    model = tf.keras.Sequential()\n",
    "    for neuron in neurons: \n",
    "        model.add(tf.keras.layers.Dense(units=neuron, activation=activation))\n",
    "    model.add(tf.keras.layers.Dense(units=10, activation=\"softmax\"))\n",
    "    model.compile(optimizer=keras.optimizers.Adam(learning_rate=0.01), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    desc = f\"{neurons}{activation}\"\n",
    "    \n",
    "    return model, desc\n",
    "\n",
    "def model_generator(generate_model, **kwargs): \n",
    "    all_models = [] \n",
    "    for neuron in kwargs.get('neurons'):\n",
    "        for activation in kwargs.get('activations'):\n",
    "            dnn_model, desc = generate_model(neuron, activation)\n",
    "            dnn_model.compile(optimizer=keras.optimizers.Adam(learning_rate=0.01), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "            all_models.append((dnn_model, desc))    \n",
    "    return all_models     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GridSearchDNN: \n",
    "    def __init__(self, model_generator, generate_model, training, valid, testing, **kwargs) -> None:\n",
    "        self.test_models = model_generator(generate_model, **kwargs)\n",
    "        self.X_train, self.y_train = training\n",
    "        self.valid = valid\n",
    "        self.X_test, self.y_test = testing\n",
    "        self.best_model = None \n",
    "        self.best_acc = None \n",
    "        self.best_desc = None\n",
    "    \n",
    "    def test_iterator(self, save_progress=False, epochs=5, save_dir=\"\", verbose=True): \n",
    "        best_model, best_acc, best_desc = None, None, None\n",
    "        for model, desc in self.test_models:\n",
    "            print(f\"--NOW TESTING {desc}--\")\n",
    "            history = model.fit(X_train, y_train, validation_data=self.valid, epochs=epochs, verbose=verbose)\n",
    "            if best_acc == None or history.history['accuracy'][-1] > best_acc:\n",
    "                best_model = model \n",
    "                best_acc = history.history['accuracy'][-1]\n",
    "                best_desc = desc \n",
    "            if save_progress:\n",
    "                model.save(f\"models/{save_dir}/{desc}\")\n",
    "            print(f\"--END TESTING {desc}--\")\n",
    "        \n",
    "        self.best_model = best_model\n",
    "        self.best_acc = best_acc\n",
    "        self.best_desc = best_desc\n",
    "                \n",
    "        return best_model, best_acc, best_desc \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = GridSearchDNN(model_generator, generate_model, (X_train, y_train), (X_valid, y_valid), (X_test, y_test), neurons=[[x,y]for x in [20, 40] for y in [20,40]], activations=['tanh', 'sigmoid', 'relu'])\n",
    "grid.test_iterator(save_progress=True, epochs=20, save_dir=\"q2.5models\")\n",
    "\n",
    "# The final best model is 40, 40 sigmoid. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  <span style=\"color:red\">**Question 2.6**</span>. Experimenting with **the label smoothing** technique\n",
    "<div style=\"text-align: right\"> <span style=\"color:red\">[5 points]</span> </div>\n",
    "\n",
    "Implement the label smoothing technique (i.e., [link for main paper](https://papers.nips.cc/paper/2019/file/f1748d6b0fd9d439f71450117eba2725-Paper.pdf) from Goeff Hinton) by yourself. Note that you cannot use the built-in label-smoothing loss function in TF2.x. Try the label smoothing technique with $\\alpha =0.1, 0.15, 0.2$ and report the performances. You need to examine the label smoothing technique with the best architecture obtained in **Question 2.5**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Insert your code here. You can add more cells if necessary\n",
    "\n",
    "def label_smoothing(y_labels, smoothing_factor, num_classes):\n",
    "    smooth_labels = y_labels * (1 - smoothing_factor) + smoothing_factor / num_classes\n",
    "    return smooth_labels \n",
    "\n",
    "alphas = [0.1, 0.15, 0.2]\n",
    "\n",
    "for alpha in alphas: \n",
    "    model, _ = generate_model(neurons=[40,40], activation='sigmoid')\n",
    "    print(f\"--TESTING {alpha}--\")\n",
    "    model.fit(X_train, label_smoothing(y_train, alpha, 10), epochs=20, verbose=0)\n",
    "    model.evaluate(X_test, label_smoothing(y_test_onehot, alpha, 10))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:#0b486b\">Part 3: Convolutional Neural Networks and Image Classification</span>\n",
    "\n",
    "**<div style=\"text-align: right\"><span style=\"color:red\">[Total marks for this part: 40 points]</span></div>**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**This part of the asssignment is designed to assess your knowledge and coding skill with Tensorflow as well as hands-on experience with training Convolutional Neural Network (CNN).**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The dataset we use for this part is a small animal dataset consisting of $5,000$ images of cats, dogs, fishes, lions, chickens, elephants, butterflies, cows, spiders, and horses, each of which has 500 images. You can download the dataset at [download here](https://drive.google.com/file/d/1bEwEx72lLrjY_Idj_FgV22atIdjtCV66/view?usp=sharing) and then decompress to the folder `datasets\\Animals` in your assignment folder.**\n",
    "\n",
    "**Your task is to build a CNN model using *TF 2.x* to classify these animals. You're provided with the module <span style=\"color:red\">models.py</span>, which you can find in the assignment folder, with some of the following classes:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. `AnimalsDatasetManager`: Support with loading and spliting the dataset into the train-val-test sets. It also supports generating next batches for training. `AnimalsDatasetManager` will be passed to CNN model for training and testing.\n",
    "2. `DefaultModel`: A base class for the CNN model.\n",
    "3. `YourModel`: The class you'll need to implement for building your CNN model. It inherits some useful attributes and functions from the base class `DefaultModel`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Firstly, we need to run the following cells to load and preprocess the Animal dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Install the package `imutils` if you have not installed yet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install imutils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('ggplot')\n",
    "%matplotlib inline\n",
    "import models\n",
    "from models import SimplePreprocessor, AnimalsDatasetManager, DefaultModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_label_folder_dict(adir):\n",
    "    sub_folders= [folder for folder in os.listdir(adir)\n",
    "                  if os.path.isdir(os.path.join(adir, folder))]\n",
    "    label_folder_dict= dict()\n",
    "    for folder in sub_folders:\n",
    "        item= {folder: os.path.abspath(os.path.join(adir, folder))}\n",
    "        label_folder_dict.update(item)\n",
    "    return label_folder_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_folder_dict= create_label_folder_dict(\"./datasets/Animals\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The below code helps to create a data manager that contains all relevant methods used to manage and process the experimental data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "butterfiles 500\n",
      "Processed 100/500\n",
      "Processed 200/500\n",
      "Processed 300/500\n",
      "Processed 400/500\n",
      "Processed 500/500\n",
      "cats 501\n",
      "Processed 100/500\n",
      "Processed 200/500\n",
      "Processed 300/500\n",
      "Processed 400/500\n",
      "Processed 500/500\n",
      "chickens 500\n",
      "Processed 100/500\n",
      "Processed 200/500\n",
      "Processed 300/500\n",
      "Processed 400/500\n",
      "Processed 500/500\n",
      "cows 500\n",
      "Processed 100/500\n",
      "Processed 200/500\n",
      "Processed 300/500\n",
      "Processed 400/500\n",
      "Processed 500/500\n",
      "dogs 501\n",
      "Processed 100/500\n",
      "Processed 200/500\n",
      "Processed 300/500\n",
      "Processed 400/500\n",
      "Processed 500/500\n",
      "elephants 500\n",
      "Processed 100/500\n",
      "Processed 200/500\n",
      "Processed 300/500\n",
      "Processed 400/500\n",
      "Processed 500/500\n",
      "fishes 500\n",
      "Processed 100/500\n",
      "Processed 200/500\n",
      "Processed 300/500\n",
      "Processed 400/500\n",
      "Processed 500/500\n",
      "horses 500\n",
      "Processed 100/500\n",
      "Processed 200/500\n",
      "Processed 300/500\n",
      "Processed 400/500\n",
      "Processed 500/500\n",
      "lions 500\n",
      "Processed 100/500\n",
      "Processed 200/500\n",
      "Processed 300/500\n",
      "Processed 400/500\n",
      "Processed 500/500\n",
      "spiders 500\n",
      "Processed 100/500\n",
      "Processed 200/500\n",
      "Processed 300/500\n",
      "Processed 400/500\n",
      "Processed 500/500\n"
     ]
    }
   ],
   "source": [
    "sp = SimplePreprocessor(width=32, height=32)\n",
    "data_manager = AnimalsDatasetManager([sp])\n",
    "data_manager.load(label_folder_dict, verbose=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the object `data_manager` has the attributes relating to *the training, validation, and testing sets* as shown belows. You can use them in training your developped models in the sequel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WTF IS THIS\n"
     ]
    }
   ],
   "source": [
    "data_manager.process_data_label()\n",
    "data_manager.train_valid_test_split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4000, 32, 32, 3) (4000,)\n",
      "(500, 32, 32, 3) (500,)\n",
      "(500, 32, 32, 3) (500,)\n",
      "['butterfiles' 'cats' 'chickens' 'cows' 'dogs' 'elephants' 'fishes'\n",
      " 'horses' 'lions' 'spiders']\n"
     ]
    }
   ],
   "source": [
    "print(data_manager.X_train.shape, data_manager.y_train.shape)\n",
    "print(data_manager.X_valid.shape, data_manager.y_valid.shape)\n",
    "print(data_manager.X_test.shape, data_manager.y_test.shape)\n",
    "print(data_manager.classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now run the **default model** built in the **models.py** file which serves as a basic baseline to start the investigation. Follow the following steps to realize how to run a model and know the built-in methods associated to a model developped in the DefaultModel class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first initialize a default model from the DefaultModel class. Basically, we can define the relevant parameters of training a model including `num_classes`, `optimizer`, `learning_rate`, `batch_size`, and `num_epochs`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "network1 = DefaultModel(name='network1',\n",
    "                       num_classes=len(data_manager.classes),\n",
    "                       optimizer='sgd',\n",
    "                       batch_size= 128,\n",
    "                       num_epochs = 20,\n",
    "                       learning_rate=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The method `build_cnn()` assists us in building your convolutional neural network. You can view the code (in the **models.py** file) of the model behind a default model to realize how simple it is. Additionally, the method `summary()` shows the architecture of a model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "network1.build_cnn()\n",
    "network1.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To train a model regarding to the datasets stored in `data_manager`, you can invoke the method `fit()` for which you can specify the batch size and number of epochs for your training. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "network1.fit(data_manager, batch_size = 64, num_epochs = 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here you can compute the accuracy of your trained model with respect to a separate testing set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "network1.compute_accuracy(data_manager.X_test, data_manager.y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below shows how you can inspect the training progress."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "network1.plot_progress()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can use the method `predict()` to predict labels for data examples in a test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "network1.predict(data_manager.X_test[0:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, the method `plot_prediction()` visualizes the predictions for a test set in which several images are chosen to show the predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "network1.plot_prediction(data_manager.X_test, data_manager.y_test, data_manager.classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:red\">**Question 3.1**</span> **After running the above cells to train the default model and observe the learning curve. Report your observation (i.e. did the model learn well? if not, what is the problem? What would you do to improve it?). Write your answer below.**\n",
    "\n",
    "<div style=\"text-align: right\"> <span style=\"color:red\">[4 points]</span> </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*#Your answer and observation here*\n",
    "According to my observation, the model did not learn well. This can be seen by the low accuracy even with the training set and the decreasing accuracy for the validation set at each epoch. The performance is not good on the test set too based on the accuracy metric. The problem might be due to the lack of hyperparameter tuning, and we could perform a Grid Search to use different values of hyperparamters such as optimizers, learning rate, epoch number and so on. However, the main problem here is with the optimizer used along with its learning rate. \n",
    ".....\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**For questions 3.2 to 3.9, you'll need to write your own model in a way that makes it easy for you to experiment with different architectures and parameters. The goal is to be able to pass the parameters to initialize a new instance of `YourModel` to build different network architectures with different parameters. Below are descriptions of some parameters for `YourModel`, which you can find in function `__init__()` for the class `DefaultModel`:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. `num_blocks`: an integer specifying the number of blocks in our network. Each block has the pattern `[conv, batch norm, activation, conv, batch norm, activation, mean pool, dropout]`. All convolutional layers have filter size $(3, 3)$, strides $(1, 1)$ and 'SAME' padding, and all mean pool layers have strides $(2, 2)$ and 'SAME' padding. The network will consists of a few blocks before applying a linear layer to output the logits for the softmax layer.\n",
    "\n",
    "2. `feature_maps`: the number of feature maps in the first block of the network. The number of feature_maps will double in each of the following block. To make it convenient for you, we already calculated the number of feature maps for each block for you in line $106$\n",
    "3. `drop_rate`: the keep probability for dropout. Setting `drop_rate` to $0.0$ means not using dropout. \n",
    "4. `batch_norm`: the batch normalization function is used or not. Setting `batch_norm` to `None` means not using batch normalization. \n",
    "5. The `skip connection` is added to the output of the second `batch norm`. Additionally, your class has a boolean property (i.e., instance variable) named `use_skip`. If `use_skip=True`, the skip connectnion is enable. Otherwise, if `use_skip=False`, the skip connectnion is disable.\n",
    "\n",
    "Below is the architecture of one block:\n",
    "\n",
    "<img src=\"Figures/OneBlock.png\" width=\"350\" align=\"center\"/>\n",
    "\n",
    "Below is the architecture of the entire deep net with `two blocks`:\n",
    "\n",
    "<img src=\"Figures/NetworkArchitecture.png\" width=\"1200\" align=\"center\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we assume that the first block has `feature_maps = feature_maps[0] = 32`. Note that the initial number of feature maps of the first block is declared in the instance variable `feature_maps` and is multiplied by $2$ in each follpwing block. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(1234)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:red\">**Question 3.2**</span> **Write the code of the `YourModel` class here. Note that this class will inherit from the `DefaultModel` class. You'll only need to re-write the code for the `build_cnn` method in the `YourModel` class from the cell below. Note that the `YourModel` class   is inherited from the `DefaultModel` class.**\n",
    "\n",
    "<div style=\"text-align: right\"> <span style=\"color:red\">[4 points]</span> </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "class YourModel(DefaultModel):\n",
    "    def __init__(self,\n",
    "                 name='network1',\n",
    "                 width=32, height=32, depth=3,\n",
    "                 num_blocks=2,\n",
    "                 feature_maps=32,\n",
    "                 num_classes=4, \n",
    "                 drop_rate=0.2,\n",
    "                 batch_norm = None,\n",
    "                 is_augmentation = False,\n",
    "                 activation_func='relu',\n",
    "                 use_skip = True,\n",
    "                 optimizer='adam',\n",
    "                 batch_size=10,\n",
    "                 num_epochs= 20,\n",
    "                 learning_rate=0.0001,\n",
    "                 verbose= True):\n",
    "        super(YourModel, self).__init__(name, width, height, depth, num_blocks, feature_maps, num_classes, drop_rate, batch_norm, is_augmentation, \n",
    "                                        activation_func, use_skip, optimizer, batch_size, num_epochs, learning_rate, verbose)\n",
    "        \n",
    "    def build_block_func(self, feature_map, input_tens):\n",
    "        CONV = layers.Conv2D(feature_map, (3,3), padding='same', strides=1)(input_tens)\n",
    "        h = layers.BatchNormalization()(CONV)\n",
    "        h = layers.Activation(self.activation_func)(h)\n",
    "        h = layers.Conv2D(feature_map, (3,3), padding='same', strides=1)(h)\n",
    "        h = layers.BatchNormalization()(h)\n",
    "        \n",
    "        if self.use_skip:\n",
    "            h = layers.Add()([h, CONV]) \n",
    "        \n",
    "        h = layers.AveragePooling2D(pool_size=(2,2), padding='same')(h)\n",
    "        h = layers.Dropout(rate=self.drop_rate)(h)\n",
    "        \n",
    "        return h\n",
    "         \n",
    "    \n",
    "    def build_cnn(self):\n",
    "        X = tf.keras.layers.Input(shape=(32,32,3))\n",
    "        block_output = X\n",
    "        for feature_map in self.feature_maps:\n",
    "            block_output = self.build_block_func(feature_map, block_output)\n",
    "        block_output = layers.Flatten()(block_output)\n",
    "        block_output = layers.Dense(self.num_classes, activation=\"softmax\")(block_output)\n",
    "        \n",
    "        self.model = tf.keras.Model(inputs=X, outputs=block_output)\n",
    "        self.model.compile(optimizer=self.optimizer, loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:red\">**Question 3.3**</span> **Once writing your own model, you need to compare two cases: (i) *using the skip connection* and (ii) *not using the skip connection*. You should set the instance variable `use_skip` to either `True` or `False`. For your runs, report which case is better and if you confront overfitting in training.**\n",
    "    \n",
    "<div style=\"text-align: right\"> <span style=\"color:red\">[6 points]</span> </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#*Write your report and observation here*\n",
    "\n",
    ".....\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_7 (InputLayer)           [(None, 32, 32, 3)]  0           []                               \n",
      "                                                                                                  \n",
      " conv2d_21 (Conv2D)             (None, 32, 32, 32)   896         ['input_7[0][0]']                \n",
      "                                                                                                  \n",
      " batch_normalization_18 (BatchN  (None, 32, 32, 32)  128         ['conv2d_21[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_9 (Activation)      (None, 32, 32, 32)   0           ['batch_normalization_18[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_22 (Conv2D)             (None, 32, 32, 32)   9248        ['activation_9[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_19 (BatchN  (None, 32, 32, 32)  128         ['conv2d_22[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " add_9 (Add)                    (None, 32, 32, 32)   0           ['batch_normalization_19[0][0]', \n",
      "                                                                  'conv2d_21[0][0]']              \n",
      "                                                                                                  \n",
      " average_pooling2d_9 (AveragePo  (None, 16, 16, 32)  0           ['add_9[0][0]']                  \n",
      " oling2D)                                                                                         \n",
      "                                                                                                  \n",
      " dropout_9 (Dropout)            (None, 16, 16, 32)   0           ['average_pooling2d_9[0][0]']    \n",
      "                                                                                                  \n",
      " conv2d_23 (Conv2D)             (None, 16, 16, 64)   18496       ['dropout_9[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_20 (BatchN  (None, 16, 16, 64)  256         ['conv2d_23[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_10 (Activation)     (None, 16, 16, 64)   0           ['batch_normalization_20[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_24 (Conv2D)             (None, 16, 16, 64)   36928       ['activation_10[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_21 (BatchN  (None, 16, 16, 64)  256         ['conv2d_24[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " add_10 (Add)                   (None, 16, 16, 64)   0           ['batch_normalization_21[0][0]', \n",
      "                                                                  'conv2d_23[0][0]']              \n",
      "                                                                                                  \n",
      " average_pooling2d_10 (AverageP  (None, 8, 8, 64)    0           ['add_10[0][0]']                 \n",
      " ooling2D)                                                                                        \n",
      "                                                                                                  \n",
      " dropout_10 (Dropout)           (None, 8, 8, 64)     0           ['average_pooling2d_10[0][0]']   \n",
      "                                                                                                  \n",
      " conv2d_25 (Conv2D)             (None, 8, 8, 128)    73856       ['dropout_10[0][0]']             \n",
      "                                                                                                  \n",
      " batch_normalization_22 (BatchN  (None, 8, 8, 128)   512         ['conv2d_25[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_11 (Activation)     (None, 8, 8, 128)    0           ['batch_normalization_22[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_26 (Conv2D)             (None, 8, 8, 128)    147584      ['activation_11[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_23 (BatchN  (None, 8, 8, 128)   512         ['conv2d_26[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " add_11 (Add)                   (None, 8, 8, 128)    0           ['batch_normalization_23[0][0]', \n",
      "                                                                  'conv2d_25[0][0]']              \n",
      "                                                                                                  \n",
      " average_pooling2d_11 (AverageP  (None, 4, 4, 128)   0           ['add_11[0][0]']                 \n",
      " ooling2D)                                                                                        \n",
      "                                                                                                  \n",
      " dropout_11 (Dropout)           (None, 4, 4, 128)    0           ['average_pooling2d_11[0][0]']   \n",
      "                                                                                                  \n",
      " flatten_3 (Flatten)            (None, 2048)         0           ['dropout_11[0][0]']             \n",
      "                                                                                                  \n",
      " dense_3 (Dense)                (None, 10)           20490       ['flatten_3[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 309,290\n",
      "Trainable params: 308,394\n",
      "Non-trainable params: 896\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "our_network_skip = YourModel(name='network1',\n",
    "                     feature_maps=32,\n",
    "                     num_classes=len(data_manager.classes),\n",
    "                     num_blocks=3,\n",
    "                     drop_rate= 0.0, \n",
    "                     batch_norm=True, \n",
    "                     use_skip = True,\n",
    "                     optimizer='adam',\n",
    "                     learning_rate= 0.001)\n",
    "our_network_skip.build_cnn()\n",
    "our_network_skip.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "125/125 [==============================] - 19s 146ms/step - loss: 2.2286 - accuracy: 0.3487 - val_loss: 2.3565 - val_accuracy: 0.1700\n",
      "Epoch 2/20\n",
      "125/125 [==============================] - 18s 142ms/step - loss: 1.5063 - accuracy: 0.5070 - val_loss: 2.1104 - val_accuracy: 0.2900\n",
      "Epoch 3/20\n",
      "125/125 [==============================] - 18s 141ms/step - loss: 1.3052 - accuracy: 0.5702 - val_loss: 1.9503 - val_accuracy: 0.3740\n",
      "Epoch 4/20\n",
      " 65/125 [==============>...............] - ETA: 8s - loss: 1.1348 - accuracy: 0.6072"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32md:\\Work Stuff\\Monash Stuff\\Year 3 Semester 1\\FIT3181-Deep-Learning\\FIT3181_Assignment_1\\FIT3181_Assignment1-2022.ipynb Cell 116\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/Work%20Stuff/Monash%20Stuff/Year%203%20Semester%201/FIT3181-Deep-Learning/FIT3181_Assignment_1/FIT3181_Assignment1-2022.ipynb#Y222sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m our_network_skip\u001b[39m.\u001b[39;49mfit(data_manager, batch_size\u001b[39m=\u001b[39;49m\u001b[39m32\u001b[39;49m, num_epochs\u001b[39m=\u001b[39;49m\u001b[39m20\u001b[39;49m)\n",
      "File \u001b[1;32md:\\Work Stuff\\Monash Stuff\\Year 3 Semester 1\\FIT3181-Deep-Learning\\FIT3181_Assignment_1\\models.py:154\u001b[0m, in \u001b[0;36mDefaultModel.fit\u001b[1;34m(self, data_manager, batch_size, num_epochs)\u001b[0m\n\u001b[0;32m    152\u001b[0m num_epochs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_epochs \u001b[39mif\u001b[39;00m num_epochs \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m num_epochs\n\u001b[0;32m    153\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel\u001b[39m.\u001b[39mcompile(optimizer\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptimizer, loss\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39msparse_categorical_crossentropy\u001b[39m\u001b[39m'\u001b[39m, metrics\u001b[39m=\u001b[39m[\u001b[39m'\u001b[39m\u001b[39maccuracy\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[1;32m--> 154\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhistory \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel\u001b[39m.\u001b[39;49mfit(x \u001b[39m=\u001b[39;49m data_manager\u001b[39m.\u001b[39;49mX_train, y \u001b[39m=\u001b[39;49m data_manager\u001b[39m.\u001b[39;49my_train, validation_data \u001b[39m=\u001b[39;49m (data_manager\u001b[39m.\u001b[39;49mX_valid, data_manager\u001b[39m.\u001b[39;49my_valid), \n\u001b[0;32m    155\u001b[0m                               epochs \u001b[39m=\u001b[39;49m num_epochs, batch_size \u001b[39m=\u001b[39;49m batch_size, verbose\u001b[39m=\u001b[39;49m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mverbose)\n",
      "File \u001b[1;32mc:\\Users\\lappy\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\utils\\traceback_utils.py:64\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     62\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     63\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 64\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m     65\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m     66\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\lappy\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\engine\\training.py:1409\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1402\u001b[0m \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mexperimental\u001b[39m.\u001b[39mTrace(\n\u001b[0;32m   1403\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[0;32m   1404\u001b[0m     epoch_num\u001b[39m=\u001b[39mepoch,\n\u001b[0;32m   1405\u001b[0m     step_num\u001b[39m=\u001b[39mstep,\n\u001b[0;32m   1406\u001b[0m     batch_size\u001b[39m=\u001b[39mbatch_size,\n\u001b[0;32m   1407\u001b[0m     _r\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m):\n\u001b[0;32m   1408\u001b[0m   callbacks\u001b[39m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1409\u001b[0m   tmp_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_function(iterator)\n\u001b[0;32m   1410\u001b[0m   \u001b[39mif\u001b[39;00m data_handler\u001b[39m.\u001b[39mshould_sync:\n\u001b[0;32m   1411\u001b[0m     context\u001b[39m.\u001b[39masync_wait()\n",
      "File \u001b[1;32mc:\\Users\\lappy\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\lappy\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    912\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    914\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 915\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[0;32m    917\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    918\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32mc:\\Users\\lappy\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:947\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    944\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n\u001b[0;32m    945\u001b[0m   \u001b[39m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m    946\u001b[0m   \u001b[39m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[1;32m--> 947\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stateless_fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)  \u001b[39m# pylint: disable=not-callable\u001b[39;00m\n\u001b[0;32m    948\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stateful_fn \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    949\u001b[0m   \u001b[39m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[0;32m    950\u001b[0m   \u001b[39m# in parallel.\u001b[39;00m\n\u001b[0;32m    951\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n",
      "File \u001b[1;32mc:\\Users\\lappy\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:2453\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2450\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[0;32m   2451\u001b[0m   (graph_function,\n\u001b[0;32m   2452\u001b[0m    filtered_flat_args) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m-> 2453\u001b[0m \u001b[39mreturn\u001b[39;00m graph_function\u001b[39m.\u001b[39;49m_call_flat(\n\u001b[0;32m   2454\u001b[0m     filtered_flat_args, captured_inputs\u001b[39m=\u001b[39;49mgraph_function\u001b[39m.\u001b[39;49mcaptured_inputs)\n",
      "File \u001b[1;32mc:\\Users\\lappy\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:1860\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1856\u001b[0m possible_gradient_type \u001b[39m=\u001b[39m gradients_util\u001b[39m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1857\u001b[0m \u001b[39mif\u001b[39;00m (possible_gradient_type \u001b[39m==\u001b[39m gradients_util\u001b[39m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1858\u001b[0m     \u001b[39mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1859\u001b[0m   \u001b[39m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1860\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_call_outputs(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_inference_function\u001b[39m.\u001b[39;49mcall(\n\u001b[0;32m   1861\u001b[0m       ctx, args, cancellation_manager\u001b[39m=\u001b[39;49mcancellation_manager))\n\u001b[0;32m   1862\u001b[0m forward_backward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1863\u001b[0m     args,\n\u001b[0;32m   1864\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1865\u001b[0m     executing_eagerly)\n\u001b[0;32m   1866\u001b[0m forward_function, args_with_tangents \u001b[39m=\u001b[39m forward_backward\u001b[39m.\u001b[39mforward()\n",
      "File \u001b[1;32mc:\\Users\\lappy\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:497\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    495\u001b[0m \u001b[39mwith\u001b[39;00m _InterpolateFunctionError(\u001b[39mself\u001b[39m):\n\u001b[0;32m    496\u001b[0m   \u001b[39mif\u001b[39;00m cancellation_manager \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 497\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39;49mexecute(\n\u001b[0;32m    498\u001b[0m         \u001b[39mstr\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msignature\u001b[39m.\u001b[39;49mname),\n\u001b[0;32m    499\u001b[0m         num_outputs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_num_outputs,\n\u001b[0;32m    500\u001b[0m         inputs\u001b[39m=\u001b[39;49margs,\n\u001b[0;32m    501\u001b[0m         attrs\u001b[39m=\u001b[39;49mattrs,\n\u001b[0;32m    502\u001b[0m         ctx\u001b[39m=\u001b[39;49mctx)\n\u001b[0;32m    503\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    504\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m    505\u001b[0m         \u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msignature\u001b[39m.\u001b[39mname),\n\u001b[0;32m    506\u001b[0m         num_outputs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    509\u001b[0m         ctx\u001b[39m=\u001b[39mctx,\n\u001b[0;32m    510\u001b[0m         cancellation_manager\u001b[39m=\u001b[39mcancellation_manager)\n",
      "File \u001b[1;32mc:\\Users\\lappy\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 54\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_Execute(ctx\u001b[39m.\u001b[39;49m_handle, device_name, op_name,\n\u001b[0;32m     55\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     56\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     57\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "our_network_skip.fit(data_manager, batch_size=32, num_epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "our_network_skip.plot_progress()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "our_network_skip.model.save(\"models/q3.3models/skip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "our_network_skip.model.evaluate(x=data_manager.X_test, y=data_manager.y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "our_network_no_skip = YourModel(name='network1',\n",
    "                     feature_maps=32,\n",
    "                     num_classes=len(data_manager.classes),\n",
    "                     num_blocks=3,\n",
    "                     drop_rate= 0.0, \n",
    "                     batch_norm=True, \n",
    "                     use_skip = False,\n",
    "                     optimizer='adam',\n",
    "                     learning_rate= 0.001)\n",
    "our_network_no_skip.build_cnn()\n",
    "our_network_no_skip.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "our_network_no_skip.fit(data_manager, batch_size=32, num_epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "our_network_no_skip.plot_progress()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "our_network_no_skip.model.save(\"models/q3.3models/noskip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "our_network_no_skip.model.evaluate(x=data_manager.X_test, y=data_manager.y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:red\">**Question 3.4**</span> **Now, let us tune the $num\\_blocks \\in \\{2,3,4\\}$, $use\\_skip \\in \\{True, False\\}$, and $learning\\_rate \\in \\{0.001, 0.0001\\}$. Write your code for this tuning and report the result of the best model on the testing set. Note that you need to show your code for tuning and evaluating on the test set to earn the full marks. During tuning, you can set the instance variable `verbose` of your model to `False` for not showing the training details of each epoch.**\n",
    " \n",
    "<div style=\"text-align: right\"> <span style=\"color:red\">[4 points]</span> </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#*Report the best parameters and the testing accuracy here*\n",
    "\n",
    "....."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Insert your code here. You can add more cells if necessary\n",
    "def generate_model(num_blocks, use_skip, learning_rate) -> tf.keras.models: \n",
    "    your_model = YourModel(name='network1',\n",
    "                feature_maps=32,\n",
    "                num_classes=len(data_manager.classes),\n",
    "                num_blocks=num_blocks,\n",
    "                drop_rate= 0.0, \n",
    "                batch_norm=True, \n",
    "                use_skip = use_skip,\n",
    "                optimizer='adam',\n",
    "                learning_rate= learning_rate)\n",
    "    your_model.build_cnn()\n",
    "    \n",
    "    desc = f\"{num_blocks}b-skip{use_skip}-lr{str(learning_rate)}\"\n",
    "    \n",
    "    return your_model.model, desc\n",
    "\n",
    "def model_generator(generate_model, **kwargs): \n",
    "    all_models = [] \n",
    "    for num_block in kwargs.get('num_blocks'):\n",
    "        for skip in kwargs.get('use_skip'):\n",
    "            for lr in kwargs.get('lrs'):\n",
    "                your_model, desc = generate_model(num_block, skip, lr)\n",
    "                all_models.append((your_model, desc))    \n",
    "    return all_models    \n",
    "\n",
    "grid_search = GridSearchDNN(\n",
    "    model_generator, \n",
    "    generate_model, \n",
    "    (data_manager.X_train, data_manager.y_train), \n",
    "    (data_manager.X_valid, data_manager.y_valid), \n",
    "    (data_manager.X_test, data_manager.y_test)) \n",
    "\n",
    "grid_search.test_iterator(save_progress=True, save_dir=\"models/q3.4\", epochs=20, verbose=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:red\">**Question 3.5**</span> **We now try to apply data augmentation to improve the performance. Extend the code of the class `YourModel` so that if the attribute `is_augmentation` is set to `True`, we apply the data augmentation. Also you need to incorporate early stopping to your training process. Specifically, you early stop the training if the valid accuracy cannot increase in three consecutive epochs.**\n",
    "   \n",
    "<div style=\"text-align: right\"> <span style=\"color:red\">[4 points]</span> </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wtire your code in the cell below. Hint that you can rewrite the code of the `fit` method to apply the data augmentation. In addition, you can copy the code of `build_cnn` method above to reuse here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class YourModel(DefaultModel):\n",
    "    def __init__(self,\n",
    "                 name='network1',\n",
    "                 width=32, height=32, depth=3,\n",
    "                 num_blocks=2,\n",
    "                 feature_maps=32,\n",
    "                 num_classes=4, \n",
    "                 drop_rate=0.2,\n",
    "                 batch_norm = None,\n",
    "                 is_augmentation = False,\n",
    "                 activation_func='relu',\n",
    "                 use_skip = True,\n",
    "                 optimizer='adam',\n",
    "                 batch_size=10,\n",
    "                 num_epochs= 20,\n",
    "                 learning_rate=0.0001):\n",
    "        super(YourModel, self).__init__(name, width, height, depth, num_blocks, feature_maps, num_classes, drop_rate, batch_norm, is_augmentation, \n",
    "                                        activation_func, use_skip, optimizer, batch_size, num_epochs, learning_rate)\n",
    "    \n",
    "    def build_block_func(self, feature_map, input_tens):\n",
    "        CONV = layers.Conv2D(feature_map, (3,3), padding='same', strides=1)(input_tens)\n",
    "        h = layers.BatchNormalization()(CONV)\n",
    "        h = layers.Activation(self.activation_func)(h)\n",
    "        h = layers.Conv2D(feature_map, (3,3), padding='same', strides=1)(h)\n",
    "        h = layers.BatchNormalization()(h)\n",
    "        \n",
    "        if self.use_skip:\n",
    "            h = layers.Add()([h, CONV]) \n",
    "        \n",
    "        h = layers.AveragePooling2D(pool_size=(2,2), padding='same')(h)\n",
    "        h = layers.Dropout(rate=self.drop_rate)(h)\n",
    "        \n",
    "        return h\n",
    "         \n",
    "    \n",
    "    def build_cnn(self):\n",
    "        X = tf.keras.layers.Input(shape=(32,32,3))\n",
    "        block_output = X\n",
    "        for feature_map in self.feature_maps:\n",
    "            block_output = self.build_block_func(feature_map, block_output)\n",
    "        block_output = layers.Flatten()(block_output)\n",
    "        block_output = layers.Dense(self.num_classes, activation=\"softmax\")(block_output)\n",
    "        \n",
    "        self.model = tf.keras.Model(inputs=X, outputs=block_output)\n",
    "        self.model.compile(optimizer=self.optimizer, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    def fit(self, data_manager, batch_size=None, num_epochs=None):\n",
    "        if self.is_augmentation:\n",
    "            datagen = ImageDataGenerator(horizontal_flip=True, fill_mode=\"nearest\", zoom_range=0.1)\n",
    "            datagen.fit(data_manager.X_train) \n",
    "            it = datagen.flow(data_manager.X_train, data_manager.y_train, batch_size=32) \n",
    "            \n",
    "            early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "                monitor=\"val_acc\",\n",
    "                patience=3, \n",
    "                mode=\"max\"\n",
    "            )\n",
    "    \n",
    "            self.model.fit(it, batch_size=self.batch_size, num_epochs=self.num_epochs, callbacks=[early_stopping])\n",
    "        else:\n",
    "            self.model.fit(data_manager, batch_size=self.batch_size, num_epochs=self.num_epochs)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:red\">**Question 3.6**</span> **Leverage your best model with the data augmentation and try to observe the difference in performance between using data augmentation and non-using it.**\n",
    "   \n",
    "<div style=\"text-align: right\"> <span style=\"color:red\">[4 points]</span> </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#*Write your answer and observation here*\n",
    "\n",
    "....."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Insert your code here. You can add more cells if necessary\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:red\">**Question 3.7**</span> **Exploring Data Mixup Technique for Improving Generalization Ability.**\n",
    "   \n",
    "<div style=\"text-align: right\"> <span style=\"color:red\">[4 points]</span> </div>\n",
    "\n",
    "Data mixup is another super-simple technique used to boost the generalization ability of deep learning models. You need to incoroporate data mixup technique to the above deep learning model and experiment its performance. There are some papers and documents for data mixup as follows:\n",
    "- Main paper for data mixup [link for main paper](https://openreview.net/pdf?id=r1Ddp1-Rb) and a good article [article link](https://www.inference.vc/mixup-data-dependent-data-augmentation/).\n",
    "\n",
    "You need to extend your model developed above, train a model using data mixup, and write your observations and comments about the result."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#*Write your answer and observation here*\n",
    "\n",
    ".....\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Insert your code here. You can add more cells if necessary\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:red\">**Question 3.8**</span> **Attack your best obtained model with PGD, MIM, and FGSM attacks with $\\epsilon= 0.0313, k=20, \\eta= 0.002$ on the testing set. Write the code for the attacks and report the robust accuracies. Also choose a random set of 20 clean images in the testing set and visualize the original and attacked images.**\n",
    "   \n",
    "<div style=\"text-align: right\"> <span style=\"color:red\">[5 points]</span> </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Insert your code here. You can add more cells if necessary\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:red\">**Question 3.9**</span> **Train a robust model using adversarial training with PGD ${\\epsilon= 0.0313, k=10, \\eta= 0.002}$. Write the code for the adversarial training and report the robust accuracies. After finishing the training, you need to store your best robust model in the folder `./models` and load the model to evaluate the robust accuracies for PGD, MIM, and FGSM attacks with $\\epsilon= 0.0313, k=20, \\eta= 0.002$ on the testing set.**\n",
    "   \n",
    "<div style=\"text-align: right\"> <span style=\"color:red\">[5 points]</span> </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Insert your code here. You can add more cells if necessary\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following is an exploring question with bonus points. It is great if you try to do this question, but it is **totally optional**. In this question, we will investigate a recent SOTA technique to improve the generalization ability of deep nets named *Sharpness-Aware Minimization (SAM)* ([link to the main paper](https://openreview.net/pdf?id=6Tm1mposlrM)).  Furthermore, SAM is simple and efficient technique, but roughly doubles the training time due to its required computation. If you have an idea to improve SAM, it would be a great paper to top-tier venues in machine learning and computer vision. Highly recommend to give it a try. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:red\">**Question 3.10**</span> (**additionally exploring question**) Read the SAM paper ([link to the main paper](https://openreview.net/pdf?id=6Tm1mposlrM)). Try to apply this techique to the best obtained model and report the results. For the purpose of implementating SAM, we can flexibly add more cells and extensions to the `model.py` file.\n",
    "\n",
    "<div style=\"text-align: right\"> <span style=\"color:red\">[5 points]</span> </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Insert your code here. You can add more cells if necessary\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--- \n",
    "**<div style=\"text-align: center\"> <span style=\"color:black\">END OF ASSIGNMENT</span> </div>**\n",
    "**<div style=\"text-align: center\"> <span style=\"color:black\">GOOD LUCK WITH YOUR ASSIGNMENT 1!</span> </div>**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.9 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "b916ba2c14536b214077dfec6c206136f3cd9dd298193f9fd8924ac064eebdc3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
