{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:#0b486b\">  FIT5215: Deep Learning (2022)</span>\n",
    "***\n",
    "*CE/Lecturer:*  **Dr Trung Le** | trunglm@monash.edu <br/> <br/>\n",
    "*Tutor:*  **Mr Tuan Nguyen**  \\[tuan.ng@monash.edu \\] |**Mr Anh Bui** \\[tuananh.bui@monash.edu\\] | **Mr Xiaohao Yang** \\[xiaohao.yang@monash.edu \\] | **Mr Md Mohaimenuzzaman** \\[md.mohaimen@monash.edu \\] |**Mr Thanh Nguyen** \\[Thanh.Nguyen4@monash.edu \\] |\n",
    "<br/> <br/>\n",
    "Faculty of Information Technology, Monash University, Australia\n",
    "******"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:#0b486b\">Tutorial 08b: RNN for Sentiment Analysis in TF 2.x</span><span style=\"color:red\"></span> #\n",
    "\n",
    "This tutorial shows you how to apply Recurrent Neural Networks in sequence classification. Particularly, we are going to explore how to implement an RNN for sentiment analysis with the dataset *IMDB movie review*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:#0b486b\">Part I: Implementation using existed dataset stored in a storage device</span><span style=\"color:red\">*****</span> ##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In many real-world projects with recurrent models, you possess the data stored in a storage device. In this case, you are required to preprocess data from scratch. In what follows, we study how to cope with this situation. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:#0b486b\">I.1. The pipeline of sentence classification</span> ###\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In what follows, we present the common pipeline of sentence classification (e.g., sentiment analysis or review analysis) from how to transform sentences as sequences of words to sequences of numbers to feed into a recurrent neural network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assume that we are learning from a tiny movie review dataset with the following sentences with labels:\n",
    "\n",
    "<img src=\"./images/movie_dataset.png\" align=\"left\" width=500/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We next extract the important or most frequent words to build up the vocabulary. Let's assume that we have the following vocabulary:\n",
    "\n",
    "<img src=\"./images/vocabulary.png\" align=\"left\" width=500/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because the vocabulary does not contain all words in the dataset, there are some words being out of the vocabulary and further assume that we employ two indices (e.g., 7 and 8) for out of vocabulary bucket. Now each word in the dataset is associated with one index which is later useful to transform sentences into sequences of indices. In addition, from the vocabulary we can conduct two dictionaries:\n",
    "- **word2indx**: keys are words and values are indices.\n",
    "- **indx2word**: keys are indices and values are words."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we assume that embedding size is $5$, meaning that each word will be embedded into a 5-dim vector space (each word becomes a 5-dim vector). For this purpose, we employ an embedding matrix as follows:\n",
    "\n",
    "<img src=\"./images/embedding_matrix.png\" align=\"left\" width=300/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that at first, this embedding matrix will be `randomly initialized` and then will be `learned` during the training process. We now explain how to use this embedding matrix to embed a mini-batch of two sentences to a 3D tensor. Assume that we have two following sentences in the mini-batch:\n",
    "1. `I like this movie`.\n",
    "2. `This is a bad movie to watch`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assume that we set sequence length (or timesteps) to 6. We need to pad the first sentence and truncate the second one as:\n",
    "1.  `I like this movie` **pad pad**.\n",
    "2. `This is a bad movie to`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We next use the vocabulary and word2indx dictionary to transform two sentences into two sequences of indices in the form of a 2D tensor with the shape $[batch\\_size, seq\\_length]$.\n",
    "1. `I like this movi` $\\rightarrow$ $[7, 1, 8, 7, 7, 7]$.\n",
    "2. `This is a bad movie to watch` $\\rightarrow$ $[8, 8, 7, 3, 7, 7]$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we use embedding matrix to transform indices to embedding vectors as:\n",
    "1. `I like this movie` $\\rightarrow$ $[7, 1, 8, 7, 7, 7]$ $\\rightarrow$ $[U_7, U_1, U_8, U_7, U_7, U_7]$.\n",
    "2. `This is a bad movie to watch` $\\rightarrow$ $[8, 8, 7, 3, 7, 7]$ $\\rightarrow$ $[U_8, U_8, U_7, U_3, U_7, U_7]$. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then concatenate two sequences of embedding vectors to a 3D tensor with the shape $[batch\\_size, seq\\_length, embed\\_size]$. This 3D tensor will be later fed to subsequent recurrent layers of cells. Note that this embedding process will be performed automatically in TF 2.x using the embedding layer.\n",
    "-  `tf.keras.layers.Embedding`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following figure details the entire process from inputting a batch of sentences, embedding to a 3D tensor, to feeding through recurrent layers.\n",
    "\n",
    "<img src=\"./images/all_in_once.png\" align=\"left\" width=1000/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:#0b486b\">I.2. Download, play around, and preprocess with the dataset</span> ###\n",
    "\n",
    "Assume that our dataset can be found online at a specific URL. We need to write code to download the dataset and store it on our storage device."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function *download_and_read(url)* supports us to download the dataset at the specific url and store to the folder *datasets* inside the current directory. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_and_read(url):\n",
    "    local_file = url.split('/')[-1]\n",
    "    local_file = local_file.replace(\"%20\", \" \")\n",
    "    p = tf.keras.utils.get_file(local_file, url, extract=True, cache_dir=\".\")\n",
    "    local_folder = os.path.join(\"datasets\", local_file.split('.')[0])\n",
    "    labeled_sentences = []\n",
    "    for labeled_filename in os.listdir(local_folder):\n",
    "        if labeled_filename.endswith(\"_labelled.txt\"):\n",
    "            with open(os.path.join(local_folder, labeled_filename), \"r\") as f:\n",
    "                for line in f:\n",
    "                    sentence, label = line.strip().split('\\t')\n",
    "                    labeled_sentences.append((sentence, label))\n",
    "    return labeled_sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now employ the above function to download the online dataset and store it on our hard disk. At this step, we also have the dataset including sentences and labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "labeled_sentences = download_and_read(\"https://archive.ics.uci.edu/ml/machine-learning-databases/\" + \"00331/sentiment%20labelled%20sentences.zip\")\n",
    "sentences = [s for (s, l) in labeled_sentences]\n",
    "labels = [int(l) for (s, l) in labeled_sentences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence: So there is no way for me to plug it in here in the US unless I go by a converter.\n",
      "Label: 0\n",
      "\n",
      "\n",
      "Sentence: Good case, Excellent value.\n",
      "Label: 1\n",
      "\n",
      "\n",
      "Sentence: Great for the jawbone.\n",
      "Label: 1\n",
      "\n",
      "\n",
      "Sentence: Tied to charger for conversations lasting more than 45 minutes.MAJOR PROBLEMS!!\n",
      "Label: 0\n",
      "\n",
      "\n",
      "Sentence: The mic is great.\n",
      "Label: 1\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for (s,l) in zip(sentences[0:5], labels[0:5]):\n",
    "    print(\"Sentence: {}\".format(s))\n",
    "    print(\"Label: {}\".format(l))\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to inspect the sentences in the dataset to work out the vocabulary and two dictionaries: *word2idx* and *idx2word*. This task is very convenient with the assistance of *tf.keras.preprocessing.text.Tokenizer*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocabulary size: 5271\n"
     ]
    }
   ],
   "source": [
    "tokenizer = tf.keras.preprocessing.text.Tokenizer()\n",
    "tokenizer.fit_on_texts(sentences)\n",
    "vocab_size = len(tokenizer.word_counts)\n",
    "print(\"vocabulary size: {:d}\".format(vocab_size))\n",
    "word2idx = tokenizer.word_index\n",
    "idx2word = {v:k for (k, v) in word2idx.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('the', 1), ('and', 2), ('i', 3), ('a', 4), ('is', 5), ('it', 6), ('to', 7), ('this', 8), ('of', 9), ('was', 10)]\n"
     ]
    }
   ],
   "source": [
    "print(list(word2idx.items())[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(1, 'the'), (2, 'and'), (3, 'i'), (4, 'a'), (5, 'is'), (6, 'it'), (7, 'to'), (8, 'this'), (9, 'of'), (10, 'was')]\n"
     ]
    }
   ],
   "source": [
    "print(list(idx2word.items())[0:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to choose the sequence length for our RNN. The sequence length should be chosen so that the truncated sentences with the sequence length contain substantial information for our task. In what follows, we investigate the percentiles to decide the sequence length."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(75, 16.0), (80, 18.0), (90, 22.0), (95, 26.0), (99, 36.0), (100, 71.0)]\n"
     ]
    }
   ],
   "source": [
    "seq_lengths = np.array([len(s.split()) for s in sentences])\n",
    "print([(p, np.percentile(seq_lengths, p)) for p\n",
    "in [75, 80, 90, 95, 99, 100]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We decide to choose $max\\_seqlen=64$ which is the percentile of $>99\\%$, hence covering almost all sentences. We then transform the dataset of sentences to that of indices. Finally, we create a Tensorflow dataset (i.e., stored in the variable *dataset*). Tensorflow dataset assists us in manipulating the data and splitting it into mini-batches later. You can find more information on Tensorflow datasets [here](https://www.tensorflow.org/api_docs/python/tf/data/Dataset)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_seqlen = 64\n",
    "# create dataset\n",
    "sentences_as_ints = tokenizer.texts_to_sequences(sentences) #transform to sequences of indices\n",
    "sentences_as_ints = tf.keras.preprocessing.sequence.pad_sequences(sentences_as_ints, maxlen=max_seqlen, padding= \"post\")  #pad some 0(s) or truncate\n",
    "labels_as_ints = np.array(labels)\n",
    "dataset = tf.data.Dataset.from_tensor_slices((sentences_as_ints, labels_as_ints))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now split the dataset to train_dataset, val_dataset, and test_dataset. Subsequently, we create batch datasets for training, valid, and test sets. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.shuffle(10000)\n",
    "test_size = len(sentences) // 3\n",
    "val_size = (len(sentences) - test_size) // 10\n",
    "test_dataset = dataset.take(test_size)\n",
    "val_dataset = dataset.skip(test_size).take(val_size)\n",
    "train_dataset = dataset.skip(test_size + val_size)\n",
    "batch_size = 64\n",
    "train_dataset = train_dataset.batch(batch_size)\n",
    "val_dataset = val_dataset.batch(batch_size)\n",
    "test_dataset = test_dataset.batch(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<BatchDataset element_spec=(TensorSpec(shape=(None, 64), dtype=tf.int32, name=None), TensorSpec(shape=(None,), dtype=tf.int32, name=None))>\n"
     ]
    }
   ],
   "source": [
    "print(train_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:#0b486b\">I.2. Building up and training the model</span> ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In what follows, we build up an RNN with the stack of two GRU cells. The input $x$ has the shape $batch\\_size \\times timesteps$, however, according to the Keras convention, we omit the $batch\\_size$. The embedding layer takes the input $x$ and transforms it to 3D tensor $batch\\_size \\times timesteps \\times embed\\_size$. When declaring an embedding layer, we need to specify vocabulary size ($vocab\\_size + 1$, and the $embed\\_size$. TF Keras will automatically infer the $timesteps$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "29/29 [==============================] - 15s 296ms/step - loss: 0.6652 - accuracy: 0.6478 - val_loss: 0.4820 - val_accuracy: 0.7900\n",
      "Epoch 2/10\n",
      "29/29 [==============================] - 6s 194ms/step - loss: 0.4094 - accuracy: 0.8211 - val_loss: 0.2304 - val_accuracy: 0.9150\n",
      "Epoch 3/10\n",
      "29/29 [==============================] - 6s 191ms/step - loss: 0.2487 - accuracy: 0.9061 - val_loss: 0.1447 - val_accuracy: 0.9650\n",
      "Epoch 4/10\n",
      "29/29 [==============================] - 6s 198ms/step - loss: 0.1515 - accuracy: 0.9450 - val_loss: 0.0805 - val_accuracy: 0.9900\n",
      "Epoch 5/10\n",
      "29/29 [==============================] - 6s 207ms/step - loss: 0.0897 - accuracy: 0.9783 - val_loss: 0.0435 - val_accuracy: 0.9900\n",
      "Epoch 6/10\n",
      "29/29 [==============================] - 6s 212ms/step - loss: 0.0670 - accuracy: 0.9789 - val_loss: 0.0465 - val_accuracy: 0.9800\n",
      "Epoch 7/10\n",
      "29/29 [==============================] - 6s 210ms/step - loss: 0.0512 - accuracy: 0.9856 - val_loss: 0.0144 - val_accuracy: 1.0000\n",
      "Epoch 8/10\n",
      "29/29 [==============================] - 6s 202ms/step - loss: 0.0297 - accuracy: 0.9900 - val_loss: 0.0288 - val_accuracy: 0.9850\n",
      "Epoch 9/10\n",
      "29/29 [==============================] - 6s 202ms/step - loss: 0.0348 - accuracy: 0.9889 - val_loss: 0.0236 - val_accuracy: 0.9900\n",
      "Epoch 10/10\n",
      "29/29 [==============================] - 6s 198ms/step - loss: 0.0211 - accuracy: 0.9933 - val_loss: 0.0208 - val_accuracy: 0.9900\n"
     ]
    }
   ],
   "source": [
    "embed_size = 128\n",
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Embedding(vocab_size+1, embed_size,\n",
    "                           mask_zero=True, # padded 0(s) at the end of each sequence of indices will be ignored during training\n",
    "                           input_shape=[None]),\n",
    "    tf.keras.layers.GRU(128, return_sequences=True),\n",
    "    tf.keras.layers.GRU(128),\n",
    "    tf.keras.layers.Dense(1, activation=\"sigmoid\")\n",
    "])\n",
    "model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "history = model.fit(train_dataset, validation_data=val_dataset, epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In case you get the error `Cannot convert a symbolic Tensor (gru/strided_slice:0) to a numpy array`, please downgrade the Numpy version to 1.19, restart the kernel, and rerun the code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 1s 59ms/step - loss: 0.0157 - accuracy: 0.9940\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.015705283731222153, 0.9940000176429749]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(test_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the declaration of `tf.keras.layers.Embedding()`, there is a quite important parameter named `mask_zero` which can be set to `True` or `False`. If we set `mask_zero = True`, zero values padded at the end of the sequence of indices for one sentence will be ignored during training. This means that we can handle variable-length sentences more elegantly. Otherwise, if we set `mask_zero = False`, those zero values padded will be treated as a normal index."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us together consider the following example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 711  632   71    0    0    0]\n",
      " [  73    8 3215   55  927    0]\n",
      " [  83   91    1  645 1253  927]]\n"
     ]
    }
   ],
   "source": [
    "raw_inputs = [\n",
    "    [711, 632, 71],\n",
    "    [73, 8, 3215, 55, 927],\n",
    "    [83, 91, 1, 645, 1253, 927],\n",
    "]\n",
    "\n",
    "# By default, this will pad using 0s; it is configurable via the \"value\" parameter.\n",
    "# Note that you could \"pre\" padding (at the beginning) or \"post\" padding (at the end).\n",
    "padded_inputs = tf.keras.preprocessing.sequence.pad_sequences(raw_inputs, padding=\"post\")\n",
    "print(padded_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[ True  True  True False False False]\n",
      " [ True  True  True  True  True False]\n",
      " [ True  True  True  True  True  True]], shape=(3, 6), dtype=bool)\n"
     ]
    }
   ],
   "source": [
    "embedding = tf.keras.layers.Embedding(input_dim=5000, output_dim=16, mask_zero=True)\n",
    "masked_output = embedding(padded_inputs)\n",
    "\n",
    "print(masked_output._keras_mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we set `mask_zero = True`, zero values marked `False` will be ignored when passing to other layers during training. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[ True  True  True False False False]\n",
      " [ True  True  True  True  True False]\n",
      " [ True  True  True  True  True  True]], shape=(3, 6), dtype=bool)\n",
      "(3, 6, 16)\n"
     ]
    }
   ],
   "source": [
    "print(masked_output._keras_mask)\n",
    "print(masked_output.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is the code to reuse the mask in the following layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 32)\n"
     ]
    }
   ],
   "source": [
    "mask = embedding.compute_mask(padded_inputs)\n",
    "h = tf.keras.layers.LSTM(32)(masked_output, mask= mask)\n",
    "print(h.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now set `mask_zero = False` to see the difference in performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "29/29 [==============================] - 9s 190ms/step - loss: 0.6943 - accuracy: 0.4961 - val_loss: 0.6932 - val_accuracy: 0.5050\n",
      "Epoch 2/10\n",
      "29/29 [==============================] - 5s 173ms/step - loss: 0.6933 - accuracy: 0.5117 - val_loss: 0.6938 - val_accuracy: 0.4750\n",
      "Epoch 3/10\n",
      "29/29 [==============================] - 5s 170ms/step - loss: 0.6934 - accuracy: 0.5022 - val_loss: 0.6930 - val_accuracy: 0.5450\n",
      "Epoch 4/10\n",
      "29/29 [==============================] - 5s 168ms/step - loss: 0.6937 - accuracy: 0.5017 - val_loss: 0.6931 - val_accuracy: 0.4950\n",
      "Epoch 5/10\n",
      "29/29 [==============================] - 5s 172ms/step - loss: 0.6934 - accuracy: 0.4972 - val_loss: 0.6931 - val_accuracy: 0.5350\n",
      "Epoch 6/10\n",
      "29/29 [==============================] - 5s 169ms/step - loss: 0.6937 - accuracy: 0.5072 - val_loss: 0.6930 - val_accuracy: 0.5100\n",
      "Epoch 7/10\n",
      "29/29 [==============================] - 5s 176ms/step - loss: 0.6933 - accuracy: 0.4983 - val_loss: 0.6942 - val_accuracy: 0.4500\n",
      "Epoch 8/10\n",
      "29/29 [==============================] - 5s 176ms/step - loss: 0.6932 - accuracy: 0.5011 - val_loss: 0.6935 - val_accuracy: 0.4600\n",
      "Epoch 9/10\n",
      "29/29 [==============================] - 5s 174ms/step - loss: 0.6932 - accuracy: 0.5050 - val_loss: 0.6931 - val_accuracy: 0.5050\n",
      "Epoch 10/10\n",
      "29/29 [==============================] - 5s 174ms/step - loss: 0.6935 - accuracy: 0.4944 - val_loss: 0.6929 - val_accuracy: 0.5350\n"
     ]
    }
   ],
   "source": [
    "embed_size = 128\n",
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Embedding(vocab_size+1, embed_size,\n",
    "                           mask_zero= False, #padded 0(s) at the end of each sequence of indices will be taken into account during training\n",
    "                           input_shape=[None]),\n",
    "    tf.keras.layers.GRU(128, return_sequences=True),\n",
    "    tf.keras.layers.GRU(128),\n",
    "    tf.keras.layers.Dense(1, activation=\"sigmoid\")\n",
    "])\n",
    "model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "history = model.fit(train_dataset, validation_data= val_dataset, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 1s 49ms/step - loss: 0.6932 - accuracy: 0.4890\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.6932116746902466, 0.48899999260902405]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(test_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:#0b486b\">Part II: Implementation with Tensorflow Keras dataset</span><span style=\"color:red\">***</span> ##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since in the tutorial, we will use *tensorflow_datasets* to download and store the IMDB movie review dataset on the hard disk, we need first to install this module using pip. Please activate your TensorFlow environment and install the package *tensorflow_datasets* using:\n",
    "- > <span style=\"color:red\"> pip install tensorflow_datasets </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first import the necessary modules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For some datasets supported by Tensorflow Keras, you can use *tensorflow_datasets* to download and preprocess. In what follows, we explicitly implement the pipeline from downloading the dataset, preprocessing it, and building up an RNN model to train this dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:#0b486b\">II.1. Download, play around, and preprocess with the dataset</span> ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mDownloading and preparing dataset Unknown size (download: Unknown size, generated: Unknown size, total: Unknown size) to ~\\tensorflow_datasets\\imdb_reviews\\plain_text\\1.0.0...\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.0319976806640625,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": 29,
       "postfix": null,
       "prefix": "Dl Completed...",
       "rate": null,
       "total": 0,
       "unit": " url",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "017a4d07b7ab43f391a5b5f37968349e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dl Completed...: 0 url [00:00, ? url/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.028992176055908203,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": 29,
       "postfix": null,
       "prefix": "Dl Size...",
       "rate": null,
       "total": 0,
       "unit": " MiB",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "18ebf0ee6c0d4c919adee141a327f1ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dl Size...: 0 MiB [00:00, ? MiB/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.012999773025512695,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": 29,
       "postfix": null,
       "prefix": "Generating splits...",
       "rate": null,
       "total": 3,
       "unit": " splits",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "388b6c4df41d4c099942513381660753",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating splits...:   0%|          | 0/3 [00:00<?, ? splits/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.01700115203857422,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": 29,
       "postfix": null,
       "prefix": "Generating train examples...",
       "rate": null,
       "total": null,
       "unit": " examples",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a0d023bebfe4fd092bad0bf626fadfb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train examples...: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.014000415802001953,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": 29,
       "postfix": null,
       "prefix": "Shuffling ~\\tensorflow_datasets\\imdb_reviews\\plain_text\\1.0.0.incompleteYKBLNW\\imdb_reviews-train.tfrecord*...",
       "rate": null,
       "total": 25000,
       "unit": " examples",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f25dae880d5a407db0592d0c1608262e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Shuffling ~\\tensorflow_datasets\\imdb_reviews\\plain_text\\1.0.0.incompleteYKBLNW\\imdb_reviews-train.tfrecord*...…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.013999462127685547,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": 29,
       "postfix": null,
       "prefix": "Generating test examples...",
       "rate": null,
       "total": null,
       "unit": " examples",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "346132a2a5bd4c45889929133e7ea60d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test examples...: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.01303410530090332,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": 29,
       "postfix": null,
       "prefix": "Shuffling ~\\tensorflow_datasets\\imdb_reviews\\plain_text\\1.0.0.incompleteYKBLNW\\imdb_reviews-test.tfrecord*...",
       "rate": null,
       "total": 25000,
       "unit": " examples",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e4e8fc8051be4396b4b2d30ffe5fc394",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Shuffling ~\\tensorflow_datasets\\imdb_reviews\\plain_text\\1.0.0.incompleteYKBLNW\\imdb_reviews-test.tfrecord*...:…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.014032125473022461,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": 29,
       "postfix": null,
       "prefix": "Generating unsupervised examples...",
       "rate": null,
       "total": null,
       "unit": " examples",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1138dd2ec91f43adae2c3b93f3df5db6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating unsupervised examples...: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.0159609317779541,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": 29,
       "postfix": null,
       "prefix": "Shuffling ~\\tensorflow_datasets\\imdb_reviews\\plain_text\\1.0.0.incompleteYKBLNW\\imdb_reviews-unsupervised.tfrecord*...",
       "rate": null,
       "total": 50000,
       "unit": " examples",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dcdb76b4ad5c4eee858aa9b4f318e157",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Shuffling ~\\tensorflow_datasets\\imdb_reviews\\plain_text\\1.0.0.incompleteYKBLNW\\imdb_reviews-unsupervised.tfrec…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mDataset imdb_reviews downloaded and prepared to ~\\tensorflow_datasets\\imdb_reviews\\plain_text\\1.0.0. Subsequent calls will reuse this data.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "datasets, info = tfds.load(\"imdb_reviews\", as_supervised=True, with_info=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys([Split('train'), Split('test'), Split('unsupervised')])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasets.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: 25000\n",
      "Test size: 25000\n"
     ]
    }
   ],
   "source": [
    "train_size = info.splits[\"train\"].num_examples\n",
    "test_size = info.splits[\"test\"].num_examples\n",
    "print(\"Train size: {}\".format(train_size))\n",
    "print(\"Test size: {}\".format(test_size))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we take one mini-batch of $5$ reviews in the training set and print out the content of those reviews with their labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review: b\"This was an absolutely terrible movie. Don't be lured in by Christopher Walken or Michael Ironside. Both are great actors, but this must simply be their worst role in history. Even their great acting could not redeem this movie's ridiculous storyline. This movie is an early nineties US propaganda piece. The most pathetic scenes were those when the Columbian rebels were making their cases for revolutions. Maria Conchita Alonso appeared phony, and her pseudo-love affair with Walken was nothing but a pathetic emotional plug in a movie that was devoid of any real meaning. I am disappointed that there are movies like this, ruining actor's like Christopher Walken's good name. I could barely sit through it.\"\n",
      "Label: 0 = Negative\n",
      "\n",
      "\n",
      "Review: b'I have been known to fall asleep during films, but this is usually due to a combination of things including, really tired, being warm and comfortable on the sette and having just eaten a lot. However on this occasion I fell asleep because the film was rubbish. The plot development was constant. Constantly slow and boring. Things seemed to happen, but with no explanation of what was causing them or why. I admit, I may have missed part of the film, but i watched the majority of it and everything just seemed to happen of its own accord without any real concern for anything else. I cant recommend this film at all.'\n",
      "Label: 0 = Negative\n",
      "\n",
      "\n",
      "Review: b'Mann photographs the Alberta Rocky Mountains in a superb fashion, and Jimmy Stewart and Walter Brennan give enjoyable performances as they always seem to do. <br /><br />But come on Hollywood - a Mountie telling the people of Dawson City, Yukon to elect themselves a marshal (yes a marshal!) and to enforce the law themselves, then gunfighters battling it out on the streets for control of the town? <br /><br />Nothing even remotely resembling that happened on the Canadian side of the border during the Klondike gold rush. Mr. Mann and company appear to have mistaken Dawson City for Deadwood, the Canadian North for the American Wild West.<br /><br />Canadian viewers be prepared for a Reefer Madness type of enjoyable howl with this ludicrous plot, or, to shake your head in disgust.'\n",
      "Label: 0 = Negative\n",
      "\n",
      "\n",
      "Review: b'This is the kind of film for a snowy Sunday afternoon when the rest of the world can go ahead with its own business as you descend into a big arm-chair and mellow for a couple of hours. Wonderful performances from Cher and Nicolas Cage (as always) gently row the plot along. There are no rapids to cross, no dangerous waters, just a warm and witty paddle through New York life at its best. A family film in every sense and one that deserves the praise it received.'\n",
      "Label: 1 = Positive\n",
      "\n",
      "\n",
      "Review: b'As others have mentioned, all the women that go nude in this film are mostly absolutely gorgeous. The plot very ably shows the hypocrisy of the female libido. When men are around they want to be pursued, but when no \"men\" are around, they become the pursuers of a 14 year old boy. And the boy becomes a man really fast (we should all be so lucky at this age!). He then gets up the courage to pursue his true love.'\n",
      "Label: 1 = Positive\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for X_batch, y_batch in datasets[\"train\"].batch(5).take(1):\n",
    "    for review, label in zip(X_batch.numpy(), y_batch.numpy()):\n",
    "        print(\"Review:\", review)\n",
    "        print(\"Label:\", label, \"= Positive\" if label else \"= Negative\")\n",
    "        print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see from some reviews, there might be some strange characters, for example *\\<br/\\>, \\<br  /\\>*. The reason is that this dataset was extracted from the HTML format. Therefore, we need to preprocess the data by removing those strange characters and splitting a review into a list of words."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Regular expression is a great tool to process texts and strings. Fortunately, Tensorflow also supports regular expression via *tf.string.regex_place* with the following syntax:\n",
    "- `tf.strings.regex_replace(input, pattern, rewrite, replace_global=True, name=None)`: we need to specify regular expression pattern in *pattern* and all substrings matched this pattern will be replaced by *rewrite*. Please refer to [here](https://github.com/google/re2/wiki/Syntax) for more detail of regular expressions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use the regular expression <span style=\"color:red\"> <br\\s*/?> </span> to find the pattern<span style=\"color:red\"><br \\[any character](one or many times) /(zero or one time)></span> and replace them by \" \". We then replace any non-character (i.e., <span style=\"color:red\">[^a-zA-Z]</span>) by \" \".\n",
    "\n",
    "We next split the reviews in the mini-batch into words and extract the first $100$ words from each review. This would only slightly drop the performance because, for most of the reviews, we can figure out its sentiment by taking a look at its first one or two sentences.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(X_batch, y_batch):\n",
    "    X_batch = tf.strings.regex_replace(X_batch, \"<br\\s*/?>\", b\" \")\n",
    "    X_batch = tf.strings.regex_replace(X_batch, b\"[^a-zA-Z]\", b\" \")\n",
    "    X_batch = tf.strings.split(X_batch)\n",
    "    X_batch = X_batch[:, :100]\n",
    "    return X_batch.to_tensor(default_value=b\"<pad>\"), y_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(5, 100), dtype=string, numpy=\n",
       " array([[b'This', b'was', b'an', b'absolutely', b'terrible', b'movie',\n",
       "         b'Don', b't', b'be', b'lured', b'in', b'by', b'Christopher',\n",
       "         b'Walken', b'or', b'Michael', b'Ironside', b'Both', b'are',\n",
       "         b'great', b'actors', b'but', b'this', b'must', b'simply', b'be',\n",
       "         b'their', b'worst', b'role', b'in', b'history', b'Even',\n",
       "         b'their', b'great', b'acting', b'could', b'not', b'redeem',\n",
       "         b'this', b'movie', b's', b'ridiculous', b'storyline', b'This',\n",
       "         b'movie', b'is', b'an', b'early', b'nineties', b'US',\n",
       "         b'propaganda', b'piece', b'The', b'most', b'pathetic', b'scenes',\n",
       "         b'were', b'those', b'when', b'the', b'Columbian', b'rebels',\n",
       "         b'were', b'making', b'their', b'cases', b'for', b'revolutions',\n",
       "         b'Maria', b'Conchita', b'Alonso', b'appeared', b'phony', b'and',\n",
       "         b'her', b'pseudo', b'love', b'affair', b'with', b'Walken',\n",
       "         b'was', b'nothing', b'but', b'a', b'pathetic', b'emotional',\n",
       "         b'plug', b'in', b'a', b'movie', b'that', b'was', b'devoid',\n",
       "         b'of', b'any', b'real', b'meaning', b'I', b'am', b'disappointed'],\n",
       "        [b'I', b'have', b'been', b'known', b'to', b'fall', b'asleep',\n",
       "         b'during', b'films', b'but', b'this', b'is', b'usually', b'due',\n",
       "         b'to', b'a', b'combination', b'of', b'things', b'including',\n",
       "         b'really', b'tired', b'being', b'warm', b'and', b'comfortable',\n",
       "         b'on', b'the', b'sette', b'and', b'having', b'just', b'eaten',\n",
       "         b'a', b'lot', b'However', b'on', b'this', b'occasion', b'I',\n",
       "         b'fell', b'asleep', b'because', b'the', b'film', b'was',\n",
       "         b'rubbish', b'The', b'plot', b'development', b'was', b'constant',\n",
       "         b'Constantly', b'slow', b'and', b'boring', b'Things', b'seemed',\n",
       "         b'to', b'happen', b'but', b'with', b'no', b'explanation', b'of',\n",
       "         b'what', b'was', b'causing', b'them', b'or', b'why', b'I',\n",
       "         b'admit', b'I', b'may', b'have', b'missed', b'part', b'of',\n",
       "         b'the', b'film', b'but', b'i', b'watched', b'the', b'majority',\n",
       "         b'of', b'it', b'and', b'everything', b'just', b'seemed', b'to',\n",
       "         b'happen', b'of', b'its', b'own', b'accord', b'without', b'any'],\n",
       "        [b'Mann', b'photographs', b'the', b'Alberta', b'Rocky',\n",
       "         b'Mountains', b'in', b'a', b'superb', b'fashion', b'and',\n",
       "         b'Jimmy', b'Stewart', b'and', b'Walter', b'Brennan', b'give',\n",
       "         b'enjoyable', b'performances', b'as', b'they', b'always',\n",
       "         b'seem', b'to', b'do', b'But', b'come', b'on', b'Hollywood',\n",
       "         b'a', b'Mountie', b'telling', b'the', b'people', b'of',\n",
       "         b'Dawson', b'City', b'Yukon', b'to', b'elect', b'themselves',\n",
       "         b'a', b'marshal', b'yes', b'a', b'marshal', b'and', b'to',\n",
       "         b'enforce', b'the', b'law', b'themselves', b'then',\n",
       "         b'gunfighters', b'battling', b'it', b'out', b'on', b'the',\n",
       "         b'streets', b'for', b'control', b'of', b'the', b'town',\n",
       "         b'Nothing', b'even', b'remotely', b'resembling', b'that',\n",
       "         b'happened', b'on', b'the', b'Canadian', b'side', b'of', b'the',\n",
       "         b'border', b'during', b'the', b'Klondike', b'gold', b'rush',\n",
       "         b'Mr', b'Mann', b'and', b'company', b'appear', b'to', b'have',\n",
       "         b'mistaken', b'Dawson', b'City', b'for', b'Deadwood', b'the',\n",
       "         b'Canadian', b'North', b'for', b'the'],\n",
       "        [b'This', b'is', b'the', b'kind', b'of', b'film', b'for', b'a',\n",
       "         b'snowy', b'Sunday', b'afternoon', b'when', b'the', b'rest',\n",
       "         b'of', b'the', b'world', b'can', b'go', b'ahead', b'with',\n",
       "         b'its', b'own', b'business', b'as', b'you', b'descend', b'into',\n",
       "         b'a', b'big', b'arm', b'chair', b'and', b'mellow', b'for', b'a',\n",
       "         b'couple', b'of', b'hours', b'Wonderful', b'performances',\n",
       "         b'from', b'Cher', b'and', b'Nicolas', b'Cage', b'as', b'always',\n",
       "         b'gently', b'row', b'the', b'plot', b'along', b'There', b'are',\n",
       "         b'no', b'rapids', b'to', b'cross', b'no', b'dangerous',\n",
       "         b'waters', b'just', b'a', b'warm', b'and', b'witty', b'paddle',\n",
       "         b'through', b'New', b'York', b'life', b'at', b'its', b'best',\n",
       "         b'A', b'family', b'film', b'in', b'every', b'sense', b'and',\n",
       "         b'one', b'that', b'deserves', b'the', b'praise', b'it',\n",
       "         b'received', b'<pad>', b'<pad>', b'<pad>', b'<pad>', b'<pad>',\n",
       "         b'<pad>', b'<pad>', b'<pad>', b'<pad>', b'<pad>', b'<pad>'],\n",
       "        [b'As', b'others', b'have', b'mentioned', b'all', b'the',\n",
       "         b'women', b'that', b'go', b'nude', b'in', b'this', b'film',\n",
       "         b'are', b'mostly', b'absolutely', b'gorgeous', b'The', b'plot',\n",
       "         b'very', b'ably', b'shows', b'the', b'hypocrisy', b'of', b'the',\n",
       "         b'female', b'libido', b'When', b'men', b'are', b'around',\n",
       "         b'they', b'want', b'to', b'be', b'pursued', b'but', b'when',\n",
       "         b'no', b'men', b'are', b'around', b'they', b'become', b'the',\n",
       "         b'pursuers', b'of', b'a', b'year', b'old', b'boy', b'And',\n",
       "         b'the', b'boy', b'becomes', b'a', b'man', b'really', b'fast',\n",
       "         b'we', b'should', b'all', b'be', b'so', b'lucky', b'at', b'this',\n",
       "         b'age', b'He', b'then', b'gets', b'up', b'the', b'courage',\n",
       "         b'to', b'pursue', b'his', b'true', b'love', b'<pad>', b'<pad>',\n",
       "         b'<pad>', b'<pad>', b'<pad>', b'<pad>', b'<pad>', b'<pad>',\n",
       "         b'<pad>', b'<pad>', b'<pad>', b'<pad>', b'<pad>', b'<pad>',\n",
       "         b'<pad>', b'<pad>', b'<pad>', b'<pad>', b'<pad>', b'<pad>']],\n",
       "       dtype=object)>,\n",
       " <tf.Tensor: shape=(5,), dtype=int64, numpy=array([0, 0, 0, 1, 1], dtype=int64)>)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocess(X_batch, y_batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:#0b486b\">II.2. Create vocabulary and relevant dictionaries</span> ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We declare *vocabulary* as a Counter to do statistics on the population of the words in the training set. We update the statistics using mini-batches of $32$. Note that for each mini-batch, we apply the function *preprocess* to preprocess the reviews in that mini-batch and split the reviews into an array of words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "vocabulary = Counter()\n",
    "for X_batch, y_batch in datasets[\"train\"].batch(32).map(preprocess):\n",
    "    for review in X_batch:\n",
    "        vocabulary.update(list(review.numpy()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now list the thirty most common words. As you can observe, the vocabulary is a list of 2-tuple of a word and its frequency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(b'the', 114272),\n",
       " (b'<pad>', 90649),\n",
       " (b'a', 65720),\n",
       " (b'and', 62647),\n",
       " (b'of', 59225),\n",
       " (b'to', 51613),\n",
       " (b'is', 44804),\n",
       " (b'I', 43737),\n",
       " (b'in', 34599),\n",
       " (b'it', 33541),\n",
       " (b'this', 28635),\n",
       " (b'that', 27640),\n",
       " (b's', 24401),\n",
       " (b'was', 24078),\n",
       " (b'movie', 22842),\n",
       " (b'The', 20992),\n",
       " (b'film', 17231),\n",
       " (b'with', 16821),\n",
       " (b'as', 16297),\n",
       " (b'for', 15917),\n",
       " (b'but', 14140),\n",
       " (b'on', 13538),\n",
       " (b't', 13319),\n",
       " (b'have', 11726),\n",
       " (b'you', 11489),\n",
       " (b'not', 11304),\n",
       " (b'are', 11290),\n",
       " (b'one', 10626),\n",
       " (b'be', 10500),\n",
       " (b'his', 9601)]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocabulary.most_common()[:30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "61865"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocabulary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now create a truncated vocabulary of the $10,000$ most common words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = 10000\n",
    "truncated_vocabulary = [word for word, count in vocabulary.most_common()[:vocab_size]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now create the dictionary *word_to_id* which allows us to quickly find the id for a given word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(b'the', 0), (b'<pad>', 1), (b'a', 2), (b'and', 3), (b'of', 4), (b'to', 5), (b'is', 6), (b'I', 7), (b'in', 8), (b'it', 9)]\n"
     ]
    }
   ],
   "source": [
    "word_to_id = {word: index for index, word in enumerate(truncated_vocabulary)}\n",
    "print(list(word_to_id.items())[0:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code aims to find a list of indices for the words in a sentence. Note that because the word \"faaaantastic\" is not in the list, it is returned None."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[32, 14, 13, None]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[word_to_id.get(word) for word in b\"This movie was faaaantastic\".split()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we create a lookup table that enables us to return 2D tensor of indices from given sentences. It is very important to note that because we limit to consider the vocabulary of the most $1000$ common words, for a given sentence in the training or testing set, some words might be out of the list. To address this issue, we set the number of *out of vocabulary* bucket $num\\_oov\\_buckets = 1000$. Therefore, a word in *out of the vocabulary* will be mapped to one of *out of bucket* index. \n",
    "\n",
    "Note that you now can imagine that we have an extended vocabulary with the vocabulary size to be equal to $vocab\\_size + num\\_oov\\_buckets= 11,000$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = tf.constant(truncated_vocabulary)\n",
    "word_ids = tf.range(len(truncated_vocabulary), dtype=tf.int64)\n",
    "vocab_init = tf.lookup.KeyValueTensorInitializer(words, word_ids)\n",
    "num_oov_buckets = 1000\n",
    "table = tf.lookup.StaticVocabularyTable(vocab_init, num_oov_buckets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, although the word \"faaaaantastic\" is not in the vocabulary, it is now mapped to the index $10791$ in the out of vocabulary bucket."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 4), dtype=int64, numpy=array([[   32,    14,    13, 10791]], dtype=int64)>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table.lookup(tf.constant([b\"This movie was faaaaantastic\".split()]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function *encode_words* returns the word indices for the words in the sentences in a mini-batch. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_words(X_batch, y_batch):\n",
    "    return table.lookup(X_batch), y_batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following code, we first apply the function *preprocess* to preprocess the training set and then apply the function *encode_words* to convert words to their indices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = datasets[\"train\"].repeat().batch(32).map(preprocess)\n",
    "train_set = train_set.map(encode_words).prefetch(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 100)\n",
      "(32,)\n",
      "(32, 100)\n",
      "(32,)\n"
     ]
    }
   ],
   "source": [
    "for X_batch, y_batch in train_set.take(2):\n",
    "    print(X_batch.shape)\n",
    "    print(y_batch.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:#0b486b\">II.3. Create an RNN model and train on the training set</span> ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In what follows, we build up an RNN with the stack of two GRU cells. The input $x$ has the shape $batch\\_size \\times timesteps$, however, according to the Keras convention, we omit the $batch\\_size$. The embedding layer takes the input $x$ and transforms it to 3D tensor $batch\\_size \\times timesteps \\times embed\\_size$. When declaring an embedding layer, we need to specify vocabulary size (extended one with the size $vocab\\_size + num\\_oov\\_buckets$, and the $embed\\_size$. TF Keras will automatically infer the $timesteps$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, None)\n",
      "(None, None, 128)\n",
      "(None, None, 128)\n",
      "(None, 64)\n"
     ]
    }
   ],
   "source": [
    "embed_size = 128\n",
    "x = tf.keras.Input(shape=[None], dtype=\"int64\")\n",
    "print(x.shape)\n",
    "h = tf.keras.layers.Embedding(vocab_size + num_oov_buckets, embed_size)(x)\n",
    "print(h.shape)\n",
    "h = tf.keras.layers.GRU(embed_size, return_sequences=True)(h)\n",
    "print(h.shape)\n",
    "h = tf.keras.layers.GRU(64)(h)\n",
    "print(h.shape)\n",
    "h = tf.keras.layers.Dense(1, activation=\"sigmoid\")(h)\n",
    "rnn_model = tf.keras.models.Model(inputs = x, outputs= h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "781/781 [==============================] - 70s 86ms/step - loss: 0.5432 - accuracy: 0.7044\n",
      "Epoch 2/2\n",
      "781/781 [==============================] - 68s 87ms/step - loss: 0.3023 - accuracy: 0.8754\n"
     ]
    }
   ],
   "source": [
    "rnn_model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "history = rnn_model.fit(train_set, steps_per_epoch=train_size // 32, epochs=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is another way to implement our RNN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "781/781 [==============================] - 97s 117ms/step - loss: 0.5482 - accuracy: 0.7073\n",
      "Epoch 2/2\n",
      "781/781 [==============================] - 90s 116ms/step - loss: 0.3333 - accuracy: 0.8589\n"
     ]
    }
   ],
   "source": [
    "embed_size = 128\n",
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Embedding(vocab_size + num_oov_buckets, embed_size,\n",
    "                           mask_zero=True, #this specifies that padded 0(s) will be ignored during training\n",
    "                           input_shape=[None]),\n",
    "    tf.keras.layers.GRU(128, return_sequences=True),\n",
    "    tf.keras.layers.GRU(128),\n",
    "    tf.keras.layers.Dense(1, activation=\"sigmoid\")\n",
    "])\n",
    "model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "history = model.fit(train_set, steps_per_epoch=train_size // 32, epochs=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now evaluate our model on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set = datasets[\"test\"].repeat(1).batch(32).map(preprocess)\n",
    "test_set = test_set.map(encode_words).prefetch(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 29s 34ms/step - loss: 0.4141 - accuracy: 0.8173\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.4141397178173065, 0.8172799944877625]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(test_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<span style=\"color:red\">Exercise 1:</span>** Replace the GRU cells with the LSTM cells and compare the results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### <span style=\"color:#0b486b\"> <div  style=\"text-align:center\">**THE END**</div> </span>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
