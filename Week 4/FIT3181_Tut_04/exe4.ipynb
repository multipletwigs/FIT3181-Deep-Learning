{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf \n",
    "import tensorflow.keras.layers as Dense \n",
    "import tensorflow.keras.models as Models \n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000,)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist = tf.keras.datasets.mnist \n",
    "(X_train_full_img, y_train_full), (X_test_img, y_test) = mnist.load_data()\n",
    "\n",
    "num_train = X_train_full_img.shape[0]\n",
    "num_test = X_test_img.shape[0]\n",
    "\n",
    "X_train_full = X_train_full_img.reshape(num_train,-1)/255.0\n",
    "X_test = X_test_img.reshape(num_test, -1)/255.0\n",
    "\n",
    "X_test[0]\n",
    "\n",
    "X_train_full.shape\n",
    "y_train_full.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1875/1875 [==============================] - 2s 693us/step - loss: 2.3170 - accuracy: 0.1044\n",
      "Epoch 2/10\n",
      "1875/1875 [==============================] - 1s 693us/step - loss: 2.3135 - accuracy: 0.1020\n",
      "Epoch 3/10\n",
      "1875/1875 [==============================] - 1s 710us/step - loss: 2.3136 - accuracy: 0.1036\n",
      "Epoch 4/10\n",
      "1875/1875 [==============================] - 1s 706us/step - loss: 2.3138 - accuracy: 0.1051\n",
      "Epoch 5/10\n",
      "1875/1875 [==============================] - 1s 694us/step - loss: 2.3147 - accuracy: 0.1028\n",
      "Epoch 6/10\n",
      "1875/1875 [==============================] - 1s 753us/step - loss: 2.3139 - accuracy: 0.1037\n",
      "Epoch 7/10\n",
      "1875/1875 [==============================] - 1s 723us/step - loss: 2.3146 - accuracy: 0.1036\n",
      "Epoch 8/10\n",
      "1875/1875 [==============================] - 1s 753us/step - loss: 2.3134 - accuracy: 0.1041\n",
      "Epoch 9/10\n",
      "1875/1875 [==============================] - 1s 728us/step - loss: 2.3143 - accuracy: 0.1041\n",
      "Epoch 10/10\n",
      "1875/1875 [==============================] - 1s 736us/step - loss: 2.3140 - accuracy: 0.1056\n",
      "313/313 [==============================] - 0s 551us/step - loss: 2.3203 - accuracy: 0.0982\n",
      "Current LR: 0.1\n",
      "Current accuracy: [2.3203079823687562, 0.0982]\n",
      "Epoch 1/10\n",
      "1875/1875 [==============================] - 2s 703us/step - loss: 2.3526 - accuracy: 0.1933\n",
      "Epoch 2/10\n",
      "1875/1875 [==============================] - 1s 720us/step - loss: 1.8040 - accuracy: 0.2691\n",
      "Epoch 3/10\n",
      "1875/1875 [==============================] - 1s 698us/step - loss: 1.8736 - accuracy: 0.2026\n",
      "Epoch 4/10\n",
      "1875/1875 [==============================] - 1s 704us/step - loss: 2.2588 - accuracy: 0.1185\n",
      "Epoch 5/10\n",
      "1875/1875 [==============================] - 1s 716us/step - loss: 2.3142 - accuracy: 0.1032\n",
      "Epoch 6/10\n",
      "1875/1875 [==============================] - 1s 691us/step - loss: 2.3149 - accuracy: 0.1042\n",
      "Epoch 7/10\n",
      "1875/1875 [==============================] - 1s 691us/step - loss: 2.3142 - accuracy: 0.1039\n",
      "Epoch 8/10\n",
      "1875/1875 [==============================] - 1s 691us/step - loss: 2.3148 - accuracy: 0.1030\n",
      "Epoch 9/10\n",
      "1875/1875 [==============================] - 1s 692us/step - loss: 2.3147 - accuracy: 0.1026\n",
      "Epoch 10/10\n",
      "1875/1875 [==============================] - 1s 694us/step - loss: 2.3145 - accuracy: 0.1020\n",
      "313/313 [==============================] - 0s 545us/step - loss: 2.3110 - accuracy: 0.0980\n",
      "Current LR: 0.1\n",
      "Current accuracy: [2.310985606276581, 0.098]\n",
      "Epoch 1/10\n",
      "1875/1875 [==============================] - 1s 642us/step - loss: 0.3771 - accuracy: 0.8849\n",
      "Epoch 2/10\n",
      "1875/1875 [==============================] - 1s 644us/step - loss: 0.1941 - accuracy: 0.9417\n",
      "Epoch 3/10\n",
      "1875/1875 [==============================] - 1s 640us/step - loss: 0.1592 - accuracy: 0.9527\n",
      "Epoch 4/10\n",
      "1875/1875 [==============================] - 1s 645us/step - loss: 0.1430 - accuracy: 0.9569\n",
      "Epoch 5/10\n",
      "1875/1875 [==============================] - 1s 651us/step - loss: 0.1315 - accuracy: 0.9609\n",
      "Epoch 6/10\n",
      "1875/1875 [==============================] - 1s 642us/step - loss: 0.1236 - accuracy: 0.9624\n",
      "Epoch 7/10\n",
      "1875/1875 [==============================] - 1s 639us/step - loss: 0.1167 - accuracy: 0.9645\n",
      "Epoch 8/10\n",
      "1875/1875 [==============================] - 1s 641us/step - loss: 0.1118 - accuracy: 0.9659\n",
      "Epoch 9/10\n",
      "1875/1875 [==============================] - 1s 642us/step - loss: 0.1051 - accuracy: 0.9676\n",
      "Epoch 10/10\n",
      "1875/1875 [==============================] - 1s 642us/step - loss: 0.1014 - accuracy: 0.9694\n",
      "313/313 [==============================] - 0s 542us/step - loss: 0.1349 - accuracy: 0.9615\n",
      "Current LR: 0.1\n",
      "Current accuracy: [0.13486700804008453, 0.9615]\n",
      "Epoch 1/10\n",
      "1875/1875 [==============================] - 1s 686us/step - loss: 0.5928 - accuracy: 0.8056\n",
      "Epoch 2/10\n",
      "1875/1875 [==============================] - 1s 687us/step - loss: 0.3983 - accuracy: 0.8869\n",
      "Epoch 3/10\n",
      "1875/1875 [==============================] - 1s 688us/step - loss: 0.3529 - accuracy: 0.9001\n",
      "Epoch 4/10\n",
      "1875/1875 [==============================] - 1s 698us/step - loss: 0.3355 - accuracy: 0.9066\n",
      "Epoch 5/10\n",
      "1875/1875 [==============================] - 1s 690us/step - loss: 0.3194 - accuracy: 0.9118\n",
      "Epoch 6/10\n",
      "1875/1875 [==============================] - 1s 706us/step - loss: 0.3184 - accuracy: 0.9120\n",
      "Epoch 7/10\n",
      "1875/1875 [==============================] - 1s 688us/step - loss: 0.3085 - accuracy: 0.9146\n",
      "Epoch 8/10\n",
      "1875/1875 [==============================] - 1s 687us/step - loss: 0.3039 - accuracy: 0.9160\n",
      "Epoch 9/10\n",
      "1875/1875 [==============================] - 1s 688us/step - loss: 0.3040 - accuracy: 0.9163\n",
      "Epoch 10/10\n",
      "1875/1875 [==============================] - 1s 685us/step - loss: 0.2962 - accuracy: 0.9180\n",
      "313/313 [==============================] - 0s 542us/step - loss: 0.3024 - accuracy: 0.9207\n",
      "Current LR: 0.01\n",
      "Current accuracy: [0.302412717137279, 0.9207]\n",
      "Epoch 1/10\n",
      "1875/1875 [==============================] - 2s 705us/step - loss: 0.3911 - accuracy: 0.8917\n",
      "Epoch 2/10\n",
      "1875/1875 [==============================] - 1s 699us/step - loss: 0.3326 - accuracy: 0.9225\n",
      "Epoch 3/10\n",
      "1875/1875 [==============================] - 1s 705us/step - loss: 0.3666 - accuracy: 0.9200\n",
      "Epoch 4/10\n",
      "1875/1875 [==============================] - 1s 703us/step - loss: 0.3950 - accuracy: 0.9168\n",
      "Epoch 5/10\n",
      "1875/1875 [==============================] - 1s 697us/step - loss: 0.4032 - accuracy: 0.9186\n",
      "Epoch 6/10\n",
      "1875/1875 [==============================] - 1s 711us/step - loss: 0.4246 - accuracy: 0.9157\n",
      "Epoch 7/10\n",
      "1875/1875 [==============================] - 1s 705us/step - loss: 0.4353 - accuracy: 0.9167\n",
      "Epoch 8/10\n",
      "1875/1875 [==============================] - 1s 704us/step - loss: 0.4605 - accuracy: 0.9157\n",
      "Epoch 9/10\n",
      "1875/1875 [==============================] - 1s 701us/step - loss: 0.5037 - accuracy: 0.9054\n",
      "Epoch 10/10\n",
      "1875/1875 [==============================] - 1s 710us/step - loss: 0.5645 - accuracy: 0.8930\n",
      "313/313 [==============================] - 0s 551us/step - loss: 0.8034 - accuracy: 0.8930\n",
      "Current LR: 0.01\n",
      "Current accuracy: [0.8034267023608128, 0.893]\n",
      "Epoch 1/10\n",
      "1875/1875 [==============================] - 2s 664us/step - loss: 0.8339 - accuracy: 0.7551\n",
      "Epoch 2/10\n",
      "1875/1875 [==============================] - 1s 664us/step - loss: 0.3298 - accuracy: 0.9048\n",
      "Epoch 3/10\n",
      "1875/1875 [==============================] - 1s 665us/step - loss: 0.2667 - accuracy: 0.9225\n",
      "Epoch 4/10\n",
      "1875/1875 [==============================] - 1s 663us/step - loss: 0.2308 - accuracy: 0.9323\n",
      "Epoch 5/10\n",
      "1875/1875 [==============================] - 1s 664us/step - loss: 0.2059 - accuracy: 0.9405\n",
      "Epoch 6/10\n",
      "1875/1875 [==============================] - 1s 665us/step - loss: 0.1888 - accuracy: 0.9446\n",
      "Epoch 7/10\n",
      "1875/1875 [==============================] - 1s 669us/step - loss: 0.1750 - accuracy: 0.9484\n",
      "Epoch 8/10\n",
      "1875/1875 [==============================] - 1s 666us/step - loss: 0.1640 - accuracy: 0.9522\n",
      "Epoch 9/10\n",
      "1875/1875 [==============================] - 1s 674us/step - loss: 0.1538 - accuracy: 0.9555\n",
      "Epoch 10/10\n",
      "1875/1875 [==============================] - 1s 665us/step - loss: 0.1453 - accuracy: 0.9577\n",
      "313/313 [==============================] - 0s 571us/step - loss: 0.1597 - accuracy: 0.9510\n",
      "Current LR: 0.01\n",
      "Current accuracy: [0.15968543688779202, 0.951]\n",
      "Epoch 1/10\n",
      "1875/1875 [==============================] - 2s 713us/step - loss: 0.3147 - accuracy: 0.9063\n",
      "Epoch 2/10\n",
      "1875/1875 [==============================] - 1s 716us/step - loss: 0.1854 - accuracy: 0.9445\n",
      "Epoch 3/10\n",
      "1875/1875 [==============================] - 1s 717us/step - loss: 0.1534 - accuracy: 0.9540\n",
      "Epoch 4/10\n",
      "1875/1875 [==============================] - 1s 719us/step - loss: 0.1353 - accuracy: 0.9596\n",
      "Epoch 5/10\n",
      "1875/1875 [==============================] - 1s 719us/step - loss: 0.1227 - accuracy: 0.9627\n",
      "Epoch 6/10\n",
      "1875/1875 [==============================] - 1s 716us/step - loss: 0.1122 - accuracy: 0.9661\n",
      "Epoch 7/10\n",
      "1875/1875 [==============================] - 1s 729us/step - loss: 0.1053 - accuracy: 0.9679\n",
      "Epoch 8/10\n",
      "1875/1875 [==============================] - 1s 719us/step - loss: 0.0998 - accuracy: 0.9704\n",
      "Epoch 9/10\n",
      "1875/1875 [==============================] - 1s 720us/step - loss: 0.0951 - accuracy: 0.9716\n",
      "Epoch 10/10\n",
      "1875/1875 [==============================] - 1s 718us/step - loss: 0.0910 - accuracy: 0.9722\n",
      "313/313 [==============================] - 0s 577us/step - loss: 0.1359 - accuracy: 0.9609\n",
      "Current LR: 0.001\n",
      "Current accuracy: [0.13594801665755019, 0.9609]\n",
      "Epoch 1/10\n",
      "1875/1875 [==============================] - 2s 715us/step - loss: 0.4285 - accuracy: 0.8731\n",
      "Epoch 2/10\n",
      "1875/1875 [==============================] - 1s 716us/step - loss: 0.2194 - accuracy: 0.9356\n",
      "Epoch 3/10\n",
      "1875/1875 [==============================] - 1s 713us/step - loss: 0.1797 - accuracy: 0.9472\n",
      "Epoch 4/10\n",
      "1875/1875 [==============================] - 1s 715us/step - loss: 0.1592 - accuracy: 0.9533\n",
      "Epoch 5/10\n",
      "1875/1875 [==============================] - 1s 713us/step - loss: 0.1454 - accuracy: 0.9572\n",
      "Epoch 6/10\n",
      "1875/1875 [==============================] - 1s 716us/step - loss: 0.1335 - accuracy: 0.9611\n",
      "Epoch 7/10\n",
      "1875/1875 [==============================] - 1s 726us/step - loss: 0.1273 - accuracy: 0.9630\n",
      "Epoch 8/10\n",
      "1875/1875 [==============================] - 1s 716us/step - loss: 0.1188 - accuracy: 0.9660\n",
      "Epoch 9/10\n",
      "1875/1875 [==============================] - 1s 721us/step - loss: 0.1133 - accuracy: 0.9679\n",
      "Epoch 10/10\n",
      "1875/1875 [==============================] - 1s 722us/step - loss: 0.1095 - accuracy: 0.9685\n",
      "313/313 [==============================] - 0s 558us/step - loss: 0.1466 - accuracy: 0.9612\n",
      "Current LR: 0.001\n",
      "Current accuracy: [0.14656340747515795, 0.9612]\n",
      "Epoch 1/10\n",
      "1875/1875 [==============================] - 1s 662us/step - loss: 2.1691 - accuracy: 0.2481\n",
      "Epoch 2/10\n",
      "1875/1875 [==============================] - 1s 658us/step - loss: 1.5000 - accuracy: 0.5951\n",
      "Epoch 3/10\n",
      "1875/1875 [==============================] - 1s 658us/step - loss: 0.8574 - accuracy: 0.7767\n",
      "Epoch 4/10\n",
      "1875/1875 [==============================] - 1s 663us/step - loss: 0.6228 - accuracy: 0.8276\n",
      "Epoch 5/10\n",
      "1875/1875 [==============================] - 1s 659us/step - loss: 0.5269 - accuracy: 0.8497\n",
      "Epoch 6/10\n",
      "1875/1875 [==============================] - 1s 658us/step - loss: 0.4708 - accuracy: 0.8642\n",
      "Epoch 7/10\n",
      "1875/1875 [==============================] - 1s 662us/step - loss: 0.4326 - accuracy: 0.8752\n",
      "Epoch 8/10\n",
      "1875/1875 [==============================] - 1s 670us/step - loss: 0.4043 - accuracy: 0.8830\n",
      "Epoch 9/10\n",
      "1875/1875 [==============================] - 1s 662us/step - loss: 0.3831 - accuracy: 0.8892\n",
      "Epoch 10/10\n",
      "1875/1875 [==============================] - 1s 661us/step - loss: 0.3655 - accuracy: 0.8938\n",
      "313/313 [==============================] - 0s 558us/step - loss: 0.3436 - accuracy: 0.9019\n",
      "Current LR: 0.001\n",
      "Current accuracy: [0.34359644743987594, 0.9019]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.1,\n",
       " <keras.optimizers.optimizer_v2.gradient_descent.SGD at 0x26f09ef6af0>,\n",
       " [0.13486700804008453, 0.9615])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class MNISTDnn(tf.keras.Model):\n",
    "    def __init__(self, n_classes=10) -> None:\n",
    "        super().__init__()\n",
    "        self.layer1 = tf.keras.layers.Dense(20, activation=\"relu\")\n",
    "        self.layer2 = tf.keras.layers.Dense(40, activation=\"relu\")\n",
    "        self.layer3 = tf.keras.layers.Dense(20, activation=\"relu\")\n",
    "        self.layer4 = tf.keras.layers.Dense(n_classes, activation=\"softmax\")\n",
    "        tf.keras.backend.set_floatx('float64')\n",
    "        \n",
    "    def call(self, input_tensor, training=False):\n",
    "        x = self.layer1(input_tensor) \n",
    "        x = self.layer2(x)\n",
    "        # if training:\n",
    "        #     x = tf.layers.dropout(x, rate=0.5)\n",
    "        x = self.layer3(x) \n",
    "        return self.layer4(x)\n",
    "    \n",
    "\n",
    "def grid_search(learning_rates, optimizers):\n",
    "    best_param = None\n",
    "    for lr in learning_rates:\n",
    "        for optimizer in optimizers:\n",
    "            mnist_mod = MNISTDnn()\n",
    "            mnist_mod.compile(optimizer=optimizer, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "            K.set_value(mnist_mod.optimizer.learning_rate, lr)\n",
    "            mnist_mod.fit(X_train_full, y_train_full, epochs=10, verbose=1) \n",
    "            dataset_accuracy = mnist_mod.evaluate(X_test, y_test)\n",
    "            print(f\"Current LR: {lr}\") \n",
    "            # print(f\"Current optimizer: {optimizer.name}\") \n",
    "            print(f\"Current accuracy: {dataset_accuracy}\")\n",
    "            if best_param is None:\n",
    "                best_param = (lr, optimizer, dataset_accuracy)\n",
    "            else:\n",
    "                if dataset_accuracy < best_param[2]:\n",
    "                    best_param = (lr, optimizer, dataset_accuracy)\n",
    "    return best_param\n",
    "\n",
    "grid_search(learning_rates=[0.1,0.01,0.001], optimizers=[tf.keras.optimizers.Adam(), tf.keras.optimizers.RMSprop(), tf.keras.optimizers.SGD(momentum=0.2)])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.9 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b916ba2c14536b214077dfec6c206136f3cd9dd298193f9fd8924ac064eebdc3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
