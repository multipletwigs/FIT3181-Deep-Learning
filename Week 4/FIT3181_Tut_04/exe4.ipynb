{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf \n",
    "import tensorflow.keras.layers as Dense \n",
    "import tensorflow.keras.models as Models \n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000,)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist = tf.keras.datasets.mnist \n",
    "(X_train_full_img, y_train_full), (X_test_img, y_test) = mnist.load_data()\n",
    "\n",
    "num_train = X_train_full_img.shape[0]\n",
    "num_test = X_test_img.shape[0]\n",
    "\n",
    "X_train_full = X_train_full_img.reshape(num_train,-1)/255.0\n",
    "X_test = X_test_img.reshape(num_test, -1)/255.0\n",
    "\n",
    "X_test[0]\n",
    "\n",
    "X_train_full.shape\n",
    "y_train_full.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1875/1875 [==============================] - 1s 604us/step - loss: 2.0360\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024BEA406A60> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024BEA406A60> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "313/313 [==============================] - 0s 436us/step - loss: 1.9347\n",
      "Current LR: 0.1\n",
      "Current accuracy: 1.9346825479507446\n",
      "1875/1875 [==============================] - 1s 598us/step - loss: 2.3596\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024BEA19F4C0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024BEA19F4C0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "313/313 [==============================] - 0s 465us/step - loss: 2.3038\n",
      "Current LR: 0.1\n",
      "Current accuracy: 2.303802925109863\n",
      "1875/1875 [==============================] - 1s 551us/step - loss: 0.3540\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024BEA1E2B80> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024BEA1E2B80> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "313/313 [==============================] - 0s 449us/step - loss: 0.1879\n",
      "Current LR: 0.1\n",
      "Current accuracy: 0.1878944614920765\n",
      "1875/1875 [==============================] - 1s 598us/step - loss: 0.5437\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024BEA377C10> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024BEA377C10> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "313/313 [==============================] - 0s 446us/step - loss: 0.3522\n",
      "Current LR: 0.01\n",
      "Current accuracy: 0.35223570847511293\n",
      "1875/1875 [==============================] - 1s 605us/step - loss: 0.3992\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024BEB61E0D0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024BEB61E0D0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "313/313 [==============================] - 0s 442us/step - loss: 0.2527\n",
      "Current LR: 0.01\n",
      "Current accuracy: 0.2527391850799322\n",
      "1875/1875 [==============================] - 1s 552us/step - loss: 0.8493\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024BEB6FD670> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024BEB6FD670> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "313/313 [==============================] - 0s 449us/step - loss: 0.3718\n",
      "Current LR: 0.01\n",
      "Current accuracy: 0.3718179503619671\n",
      "1875/1875 [==============================] - 1s 598us/step - loss: 0.3114\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024BEB7D8700> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024BEB7D8700> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "313/313 [==============================] - 0s 449us/step - loss: 0.2066\n",
      "Current LR: 0.001\n",
      "Current accuracy: 0.206593747651577\n",
      "1875/1875 [==============================] - 1s 605us/step - loss: 0.3881\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024BEB8C9280> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024BEB8C9280> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "313/313 [==============================] - 0s 449us/step - loss: 0.2207\n",
      "Current LR: 0.001\n",
      "Current accuracy: 0.2207324832111597\n",
      "1875/1875 [==============================] - 1s 579us/step - loss: 2.1484\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024BEBA2B430> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024BEBA2B430> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "313/313 [==============================] - 0s 452us/step - loss: 1.8679\n",
      "Current LR: 0.001\n",
      "Current accuracy: 1.8678690731048584\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.1, <keras.optimizer_v2.rmsprop.RMSprop at 0x24bea017520>, 2.303802925109863)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class MNISTDnn(tf.keras.Model):\n",
    "    def __init__(self, n_classes=10) -> None:\n",
    "        super().__init__()\n",
    "        self.layer1 = tf.keras.layers.Dense(20, activation=\"relu\")\n",
    "        self.layer2 = tf.keras.layers.Dense(40, activation=\"relu\")\n",
    "        self.layer3 = tf.keras.layers.Dense(20, activation=\"relu\")\n",
    "        self.layer4 = tf.keras.layers.Dense(n_classes, activation=\"softmax\")\n",
    "        tf.keras.backend.set_floatx('float64')\n",
    "        \n",
    "    def call(self, input_tensor, training=False):\n",
    "        x = self.layer1(input_tensor) \n",
    "        x = self.layer2(x)\n",
    "        # if training:\n",
    "        #     x = tf.layers.dropout(x, rate=0.5)\n",
    "        x = self.layer3(x) \n",
    "        return self.layer4(x)\n",
    "    \n",
    "\n",
    "def grid_search(learning_rates, optimizers):\n",
    "    best_param = None\n",
    "    for lr in learning_rates:\n",
    "        for optimizer in optimizers:\n",
    "            mnist_mod = MNISTDnn()\n",
    "            mnist_mod.compile(optimizer=optimizer, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "            K.set_value(mnist_mod.optimizer.learning_rate, lr)\n",
    "            mnist_mod.fit(X_train_full, y_train_full, epochs=1) \n",
    "            dataset_accuracy = mnist_mod.evaluate(X_test, y_test)\n",
    "            print(f\"Current LR: {lr}\") \n",
    "            # print(f\"Current optimizer: {optimizer.name}\") \n",
    "            print(f\"Current accuracy: {dataset_accuracy}\")\n",
    "            if best_param is None:\n",
    "                best_param = (lr, optimizer, dataset_accuracy)\n",
    "            else:\n",
    "                if dataset_accuracy > best_param[2]:\n",
    "                    best_param = (lr, optimizer, dataset_accuracy)\n",
    "    return best_param\n",
    "\n",
    "grid_search(learning_rates=[0.1,0.01,0.001], optimizers=[tf.keras.optimizers.Adam(), tf.keras.optimizers.RMSprop(), tf.keras.optimizers.SGD(momentum=0.2)])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.9 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b916ba2c14536b214077dfec6c206136f3cd9dd298193f9fd8924ac064eebdc3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
